{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "musical-gilbert",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "direct-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pickle\n",
    "import catboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-crawford",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "growing-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAWDATADIR = '../data/raw'\n",
    "DATADIR = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-thanks",
   "metadata": {},
   "source": [
    "## Словарь по целевым постам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aggressive-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "kirensk_dict = {\n",
    "    'name': 'Киренск',\n",
    "    'id': 3019,\n",
    "    'meteo_st': [30028, 30219, 30328, 30337, 30433, 30230],\n",
    "    'gydro_st': [3087, 3021],\n",
    "    'id_influencer': [],\n",
    "    'std_sq': 185.35707752426708\n",
    "}\n",
    "\n",
    "vitim_dict = {\n",
    "    'name': 'Витим',\n",
    "    'id': 3027,\n",
    "    'meteo_st': [24713, 24726, 24817, 30356, 30471, 30372, 30069, 30253, 30252, 24923],\n",
    "    'gydro_st': [3106, 3555, 3024, 3554, 3028, 3029, 3030, 3031, 3032],\n",
    "    'id_influencer': [3019],\n",
    "    'std_sq': 1223.8071616577856\n",
    "}\n",
    "\n",
    "peledui_dict = {\n",
    "    'name': 'Пеледуй',\n",
    "    'id': 3028,\n",
    "    'meteo_st': [24713, 24726, 24817, 30356, 30471, 30372, 30069, 30253, 30252, 24923],\n",
    "    'gydro_st': [3106, 3555, 3024, 3554, 3027, 3029, 3030, 3031, 3032],\n",
    "    'id_influencer': [3019, 3027],\n",
    "    'std_sq': 1357.4062812989373\n",
    "}\n",
    "\n",
    "krestovskiy_dict = {\n",
    "    'name': 'Крестовский Лесоучасток',\n",
    "    'id': 3029,\n",
    "    'meteo_st': [24713, 24726, 24817, 30356, 30471, 30372, 30069, 30253, 30252, 24923],\n",
    "    'gydro_st': [3106, 3555, 3024, 3554, 3027, 3028, 3030, 3031, 3032],\n",
    "    'id_influencer': [3019, 3027, 3028],\n",
    "    'std_sq': 1520.7730161870682\n",
    "}\n",
    "\n",
    "lensk_dict = {\n",
    "    'name': 'Ленск',\n",
    "    'id': 3030,\n",
    "    'meteo_st': [24713, 24726, 24817, 30356, 30471, 30372, 30069, 30253, 30252, 24923],\n",
    "    'gydro_st': [3106, 3555, 3024, 3554, 3027, 3028, 3029, 3031, 3032],\n",
    "    'id_influencer': [3019, 3027, 3028, 3029],\n",
    "    'std_sq': 1765.9217904996142\n",
    "}\n",
    "\n",
    "olekminsk_dict = {\n",
    "    'name': 'Олекминск',\n",
    "    'id': 3035,\n",
    "    'meteo_st': [24538,24738,24641,24933,30089,30385,30493,30393,31102,31004,24951,24944],\n",
    "    'gydro_st': [3180,3169,3036,3037,3038],\n",
    "    'id_influencer': [3019, 3027, 3028, 3029, 3030],\n",
    "    'std_sq': 765.3703832632036\n",
    "}\n",
    "\n",
    "pokrovsk_dict = {\n",
    "    'name': 'Покровск',\n",
    "    'id': 3041,\n",
    "    'meteo_st': [31137,31026,24967,24966,24641,24643,24661,24671,24763],\n",
    "    'gydro_st': [3042,3045,3047,3048],\n",
    "    'id_influencer': [3019, 3027, 3028, 3029, 3030, 3035],\n",
    "    'std_sq': 443.5766934006718\n",
    "}\n",
    "\n",
    "yakutsk_dict = {\n",
    "    'name': 'Якутск',\n",
    "    'id': 3045,\n",
    "    'meteo_st': [31137,31026,24967,24966,24641,24643,24661,24671,24763],\n",
    "    'gydro_st': [3042,3041,3047,3048],\n",
    "    'id_influencer': [3019, 3027, 3028, 3029, 3030, 3035, 3041],\n",
    "    'std_sq': 579.1353554017562\n",
    "}\n",
    "\n",
    "batamay_dict = {\n",
    "    'name': 'Батамай',\n",
    "    'id': 3230,\n",
    "    'meteo_st': [31137,31026,24967,24966,24641,24643,24661,24671,24763],\n",
    "    'gydro_st': [3229,3050],\n",
    "    'id_influencer': [3019, 3027, 3028, 3029, 3030, 3035, 3041, 3045],\n",
    "    'std_sq': 516.6669876251401\n",
    "}\n",
    "\n",
    "sangar_dict = {\n",
    "    'name': 'Сангар',\n",
    "    'id': 3050,\n",
    "    'meteo_st': [31137,31026,24967,24966,24641,24643,24661,24671,24763],\n",
    "    'gydro_st': [3229,3230],\n",
    "    'id_influencer': [3019, 3027, 3028, 3029, 3030, 3035, 3041, 3045, ],\n",
    "    'std_sq': 612.0471238561079\n",
    "}\n",
    "\n",
    "target_stations = [\n",
    "    kirensk_dict, \n",
    "    vitim_dict, \n",
    "    peledui_dict, \n",
    "    krestovskiy_dict, \n",
    "    lensk_dict, \n",
    "    olekminsk_dict, \n",
    "    pokrovsk_dict,\n",
    "    yakutsk_dict,\n",
    "    batamay_dict,\n",
    "    sangar_dict\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-tract",
   "metadata": {},
   "source": [
    "# Методы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-gross",
   "metadata": {},
   "source": [
    "## make_gydro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "challenging-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gydro_df(train_df, station_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Формирует датасет с гидрологическими данными\n",
    "    \"\"\"\n",
    "\n",
    "    tr_data = df_preprocessing(train_df, station_dict['id'])\n",
    "\n",
    "    # соберём данные со смежных постов, выделенных в словаре по данному целевому посту\n",
    "    mapper = dict()\n",
    "    use_feature = ['date', 'stage_avg', 'stage_min','stage_max', 'temp', 'water_code', 'ice_thickness','snow_height', \n",
    "                   'place', 'discharge']\n",
    "\n",
    "    for n, st in enumerate(station_dict['gydro_st']):\n",
    "        if n == 0:\n",
    "            # данные с поста\n",
    "            df = df_preprocessing(train_df, st)\n",
    "            df = df[use_feature]\n",
    "            for col in [x for x in use_feature if x not in ['date']]:\n",
    "                mapper[col] = f'{col}_{st}'\n",
    "            gydro_st = df.rename(columns=mapper)\n",
    "        else:\n",
    "            # данные с поста\n",
    "            df = df_preprocessing(train_df, st)\n",
    "            df = df[use_feature]\n",
    "            for col in [x for x in use_feature if x not in ['date']]:\n",
    "                mapper[col] = f'{col}_{st}'\n",
    "            df.rename(columns=mapper, inplace=True)\n",
    "            gydro_st = pd.merge(gydro_st, df, how='outer', on='date')\n",
    "            \n",
    "    # сводные данные по целевому посту и его окресных гидропостов\n",
    "    return pd.merge(tr_data, gydro_st, how='left', on='date').fillna(-777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-pipeline",
   "metadata": {},
   "source": [
    "## make_meteo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "favorite-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meteo_df(meteo_df, stations_id, verbose=False):\n",
    "    \"\"\"\n",
    "    Формирует датасет с метеорологическим данными\n",
    "    \"\"\"\n",
    "    # Замена np.nan'ами неподтверждённых или опровергнутых данных\n",
    "    _qual_cols = list(meteo_df.filter(regex='_qual$').columns)\n",
    "    if verbose: print(meteo_df.shape)\n",
    "    for col in _qual_cols:\n",
    "        meteo_df = mute_untrastable(meteo_df, col)\n",
    "    if verbose: print(meteo_df.shape)\n",
    "\n",
    "    features = pd.Series(_qual_cols)\n",
    "    spl_feat = []\n",
    "    for n, f in enumerate(features):\n",
    "        spl = features.values[n].split('_')\n",
    "        spl_feat.append(('_'.join(spl[:len(spl)-1])))\n",
    "\n",
    "    use_feature = ['station_id', 'date_local', 'month_local'] + spl_feat\n",
    "\n",
    "    meteo_data = meteo_df[use_feature].copy()\n",
    "    if verbose: print(meteo_data.shape)\n",
    "    del meteo_df\n",
    "    gc.collect()\n",
    "    \n",
    "    # аггрегация данных с дискретностью 1 день\n",
    "    meteo_1day = meteo_data.groupby(['station_id', 'date_local']).median()\n",
    "    meteo_1day.reset_index(inplace=True)\n",
    "    if verbose: print(meteo_1day.shape)\n",
    "    del meteo_data\n",
    "    gc.collect()\n",
    "    \n",
    "    mapper = dict()\n",
    "    use_feature = ['date_local', 'month_local'] + spl_feat\n",
    "\n",
    "    # берём данные по нужным станциям\n",
    "    for n, st in enumerate(stations_id):\n",
    "        if verbose: print(n, st)\n",
    "        if n == 0:\n",
    "            df = meteo_data_processing(meteo_1day, st)\n",
    "            df = df[use_feature]\n",
    "            if verbose: print(df.shape)\n",
    "            for col in spl_feat:\n",
    "                mapper[col] = f'{col}_{st}'\n",
    "            meteo_st = df.rename(columns=mapper)\n",
    "        else:\n",
    "            df = meteo_data_processing(meteo_1day, st)\n",
    "            df = df[use_feature]\n",
    "            if verbose: print(df.shape)\n",
    "            for col in spl_feat:\n",
    "                mapper[col] = f'{col}_{st}'\n",
    "            df.rename(columns=mapper, inplace=True)\n",
    "            meteo_st = pd.merge(meteo_st, df, how='outer', on=['date_local', 'month_local'])\n",
    "            \n",
    "        \n",
    "    # находим значения для заполнения праметров с пропусками, учитывая специфику каждого месяца\n",
    "    features_dict = dict()\n",
    "    features = [x for x in meteo_st.columns if x not in ['date_local', 'month_local']]\n",
    "    for f in features:\n",
    "        features_dict[f] = dict()\n",
    "    for feature in features:\n",
    "        for i in range(1, 13):\n",
    "            val = meteo_st.loc[meteo_st.month_local == i, feature].median()\n",
    "            if (val is not np.nan)|(val is not pd.NA)|(val != 'nan'):\n",
    "                features_dict[feature][i] = val\n",
    "            else:\n",
    "                features_dict[feature][i] = -777\n",
    "    # заполняем пропуски\n",
    "    for col in features:\n",
    "        for i in range(1,13):\n",
    "            meteo_st.loc[(meteo_st.month_local == i)&(meteo_st[col].isna()), col] = features_dict[col][i]\n",
    "                \n",
    "    meteo_st.fillna(-777, inplace=True)\n",
    "    \n",
    "    return meteo_st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-astronomy",
   "metadata": {},
   "source": [
    "## df_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "homeless-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preprocessing(df, station_id, verbose=False):\n",
    "    \"\"\"\n",
    "    Предобработка данных по указанной гидростанции станции\n",
    "    \"\"\"\n",
    "    tr_data = df[(df.station_id == station_id)].copy()\n",
    "\n",
    "    # если замер льда не делали, то пусть 0 будет такой категорией\n",
    "    tr_data['place'].fillna(0, inplace=True)\n",
    "    # water_code и place должны быть категориальными\n",
    "    tr_data['water_code'] = tr_data['water_code'].astype('str')\n",
    "    tr_data['place'] = tr_data['place'].astype('int8')\n",
    "    \n",
    "    # проверка признаков на наличие пропусков\n",
    "    na_features = []\n",
    "    if verbose: print('Пропуски:')\n",
    "    for col in tr_data.columns:\n",
    "        cnt = tr_data[col].isna().sum()\n",
    "        if cnt > 0:\n",
    "            if verbose: print(col, ':', cnt)\n",
    "            na_features.append(col)\n",
    "    if verbose: print()\n",
    "    if len(na_features) > 0:\n",
    "        # находим значения для заполнения праметров с пропусками, учитывая специфику каждого месяца\n",
    "        na_features_dict = dict()\n",
    "        for f in na_features:\n",
    "            na_features_dict[f] = dict()\n",
    "        for feature in na_features:\n",
    "            for i in range(1, 13):\n",
    "                val = tr_data.loc[tr_data.month == i, feature].median()\n",
    "                # признак если среднего расхода воды не знаем или не замеряется на посту\n",
    "                if (val is np.nan)&(feature == 'discharge'):\n",
    "                    na_features_dict[feature][i] = -1\n",
    "                elif val is np.nan:\n",
    "                    na_features_dict[feature][i] = 0.0\n",
    "                else:\n",
    "                    na_features_dict[feature][i] = val\n",
    "        # заполняем пропуски\n",
    "        for col in na_features:\n",
    "            for i in range(1,13):\n",
    "                tr_data.loc[(tr_data.month == i)&(tr_data[col].isna()), col] = na_features_dict[col][i]\n",
    "            \n",
    "    return tr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-league",
   "metadata": {},
   "source": [
    "## mute_untrastable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dependent-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mute_untrastable(df, feature):\n",
    "    \"\"\"\n",
    "    Замена NaN'ами неподтверждённых или опровергнутых данных\n",
    "    feature - фича с суфиксом _qual\n",
    "    \"\"\"\n",
    "    spl = feature.split('_')\n",
    "    spl_feat = ('_').join(spl[:len(spl)-1])\n",
    "    \n",
    "    df.loc[df[feature] > 2, spl_feat] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-groove",
   "metadata": {},
   "source": [
    "## meteo_data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "consistent-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteo_data_processing(meteo_1day, station_id, verbose=False):\n",
    "    \"\"\"\n",
    "    Предобработка метеоданных\n",
    "    meteo_1day - dataframe с метеоданными, аггрегированные за 1 день\n",
    "    \"\"\"\n",
    "    \n",
    "    df = meteo_1day[(meteo_1day.station_id == station_id)].copy()\n",
    "    \n",
    "    # проверка признаков на наличие пропусков\n",
    "    na_features = []\n",
    "    if verbose: print('Пропуски:')\n",
    "    for col in df.columns:\n",
    "        cnt = df[col].isna().sum()\n",
    "        if cnt > 0:\n",
    "            if verbose: print(col, ':', cnt)\n",
    "            na_features.append(col)\n",
    "            \n",
    "    if len(na_features) > 0:\n",
    "        # находим значения для заполнения праметров с пропусками, учитывая специфику каждого месяца\n",
    "        na_features_dict = dict()\n",
    "        for f in na_features:\n",
    "            na_features_dict[f] = dict()\n",
    "        for feature in na_features:\n",
    "            for i in range(1, 13):\n",
    "                val = df.loc[df.month_local == i, feature].median()\n",
    "                if (val is np.nan):\n",
    "                    na_features_dict[feature][i] = -777\n",
    "                else:\n",
    "                    na_features_dict[feature][i] = val\n",
    "                        \n",
    "        # заполняем пропуски\n",
    "        for col in na_features:\n",
    "            for i in range(1,13):\n",
    "                df.loc[(df.month_local == i)&(df[col].isna()), col] = na_features_dict[col][i]\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-natural",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-conflict",
   "metadata": {},
   "source": [
    "verbose=False\n",
    "for st_dict in target_stations:\n",
    "    print(st_dict['name'])\n",
    "    # формируем датасет\n",
    "    print('формируем датасет')\n",
    "    gydro_df = make_gydro_df(\n",
    "        pd.read_csv(f'{RAWDATADIR}/track_2_package/train.csv', parse_dates=['date']),\n",
    "        st_dict\n",
    "    )\n",
    "    if verbose: print('gydro_df', gydro_df.shape)\n",
    "\n",
    "    meteo_df = make_meteo_df(\n",
    "        pd.read_csv(f'{RAWDATADIR}/track_2_package/meteo_3hours.csv', parse_dates=['date_local']),\n",
    "        st_dict['meteo_st']\n",
    "    )\n",
    "    if verbose: print('meteo_df', meteo_df.shape)\n",
    "\n",
    "    train_data = pd.merge(gydro_df, meteo_df.rename(columns={'date_local': 'date'}), how='left', on='date')\n",
    "    if verbose: print('train_data',train_data.shape)\n",
    "\n",
    "    train_data.fillna(-777, inplace=True)\n",
    "    if verbose: print('NaNs', sum(train_data.isna().sum()))\n",
    "    if verbose: print('train_data', train_data.shape)\n",
    "\n",
    "    with open(f\"datasets/{st_dict['name']}_sub_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "overhead-navigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3019: 'Киренск',\n",
       " 3027: 'Витим',\n",
       " 3028: 'Пеледуй',\n",
       " 3029: 'Крестовский Лесоучасток',\n",
       " 3030: 'Ленск',\n",
       " 3035: 'Олекминск',\n",
       " 3041: 'Покровск',\n",
       " 3045: 'Якутск',\n",
       " 3230: 'Батамай',\n",
       " 3050: 'Сангар'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = dict()\n",
    "\n",
    "for st in target_stations:\n",
    "    mapper[st['id']] = st['name']\n",
    "    \n",
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sacred-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "\n",
    "verbose=False\n",
    "for i in range(0, len(submit), 7):\n",
    "    if verbose: print(i)\n",
    "    target_date = submit.loc[i, 'date']\n",
    "    target_st = submit.loc[i, 'station_id']\n",
    "    data_date = target_date - pd.Timedelta(days=1)\n",
    "    if verbose: print('target_date',target_date)\n",
    "    if verbose: print('target_st',target_st)\n",
    "    if verbose: print('data_date',data_date)\n",
    "    with open(f\"datasets/{mapper[target_st]}_sub_data.pkl\", 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    input_data = data[(data.station_id==target_st)&(data.date==data_date)]\n",
    "    if verbose: display(input_data)\n",
    "    wcode = list(input_data.filter(regex='water_code').columns)\n",
    "    target = list(input_data.filter(regex='delta_stage_max').columns)\n",
    "    X = input_data.drop(['station_id','date','year']+wcode+target,axis=1).to_numpy()\n",
    "    if verbose: print('X.shape', X.shape)\n",
    "    if len(X) > 0:\n",
    "        for j in range(1,8):\n",
    "            with open(f\"models/model_{target_st}_{j}.pkl\", 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            submit.loc[i, 'delta_stage_max'] = model.predict(X)\n",
    "            i += 1\n",
    "    else:\n",
    "        submit.loc[i, 'delta_stage_max'] = np.nan\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quick-merit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1993</td>\n",
       "      <td>3045</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>2.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1993</td>\n",
       "      <td>3045</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>2.351785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1993</td>\n",
       "      <td>3045</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>-2.025719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1993</td>\n",
       "      <td>3045</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>-1.409916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1993</td>\n",
       "      <td>3045</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>-0.028481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>2013</td>\n",
       "      <td>3045</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>2013</td>\n",
       "      <td>3045</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>2013</td>\n",
       "      <td>3045</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>2013</td>\n",
       "      <td>3045</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>2013</td>\n",
       "      <td>3045</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  station_id  month  day       date  delta_stage_max\n",
       "231   1993        3045      4  111 1993-04-21         2.112000\n",
       "232   1993        3045      4  112 1993-04-22         2.351785\n",
       "233   1993        3045      4  113 1993-04-23        -2.025719\n",
       "234   1993        3045      4  114 1993-04-24        -1.409916\n",
       "235   1993        3045      4  115 1993-04-25        -0.028481\n",
       "...    ...         ...    ...  ...        ...              ...\n",
       "2424  2013        3045      5  134 2013-05-14              NaN\n",
       "2425  2013        3045      5  135 2013-05-15              NaN\n",
       "2426  2013        3045      5  136 2013-05-16              NaN\n",
       "2427  2013        3045      5  137 2013-05-17              NaN\n",
       "2428  2013        3045      5  138 2013-05-18              NaN\n",
       "\n",
       "[252 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[submit.station_id==3045]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-makeup",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "identified-peeing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11604, 33)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Киренск\n",
    "gydro_df = make_gydro_df(\n",
    "    pd.read_csv(f'{RAWDATADIR}/track_2_package/train.csv', parse_dates=['date']),\n",
    "    kirensk_dict\n",
    ")\n",
    "gydro_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "typical-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12310, 218)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_df = make_meteo_df(\n",
    "    pd.read_csv(f'{RAWDATADIR}/track_2_package/meteo_3hours.csv', parse_dates=['date_local']),\n",
    "    kirensk_dict['meteo_st']\n",
    ")\n",
    "meteo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "processed-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11604, 250)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(gydro_df, meteo_df.rename(columns={'date_local': 'date'}), how='left', on='date')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "outside-final",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70631"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "covered-diana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fillna(-777, inplace=True)\n",
    "sum(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gentle-permit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11597, 257)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['delta_stage_max_1'] = data.delta_stage_max.shift(1)\n",
    "data['delta_stage_max_2'] = data.delta_stage_max.shift(2)\n",
    "data['delta_stage_max_3'] = data.delta_stage_max.shift(3)\n",
    "data['delta_stage_max_4'] = data.delta_stage_max.shift(4)\n",
    "data['delta_stage_max_5'] = data.delta_stage_max.shift(5)\n",
    "data['delta_stage_max_6'] = data.delta_stage_max.shift(6)\n",
    "data['delta_stage_max_7'] = data.delta_stage_max.shift(7)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accepting-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{kirensk_dict['name']}_train_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stable-navigation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['station_id',\n",
       " 'date',\n",
       " 'stage_avg',\n",
       " 'stage_min',\n",
       " 'stage_max',\n",
       " 'temp',\n",
       " 'water_code',\n",
       " 'ice_thickness',\n",
       " 'snow_height',\n",
       " 'place',\n",
       " 'discharge',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'delta_stage_max',\n",
       " 'stage_avg_3087',\n",
       " 'stage_min_3087',\n",
       " 'stage_max_3087',\n",
       " 'temp_3087',\n",
       " 'water_code_3087',\n",
       " 'ice_thickness_3087',\n",
       " 'snow_height_3087',\n",
       " 'place_3087',\n",
       " 'discharge_3087',\n",
       " 'stage_avg_3021',\n",
       " 'stage_min_3021',\n",
       " 'stage_max_3021',\n",
       " 'temp_3021',\n",
       " 'water_code_3021',\n",
       " 'ice_thickness_3021',\n",
       " 'snow_height_3021',\n",
       " 'place_3021',\n",
       " 'discharge_3021',\n",
       " 'month_local',\n",
       " 'horizontal_visibility_30028',\n",
       " 'cloud_amount_total_30028',\n",
       " 'cloud_amount_low_level_30028',\n",
       " 'cloud_form_high_level_30028',\n",
       " 'cloud_form_middle_level_30028',\n",
       " 'cloud_form_vertical_develop_30028',\n",
       " 'cloud_form_strat_stratocum_30028',\n",
       " 'cloud_form_strat_rain_30028',\n",
       " 'cloud_base_altitude_30028',\n",
       " 'cloud_below_station_30028',\n",
       " 'soil_surface_condition_30028',\n",
       " 'weather_before_30028',\n",
       " 'weather_30028',\n",
       " 'wind_direction_30028',\n",
       " 'wind_speed_aver_30028',\n",
       " 'wind_speed_max_30028',\n",
       " 'precipitation_30028',\n",
       " 'soil_surface_temperature_30028',\n",
       " 'soil_surface_alco_temperature_30028',\n",
       " 'soil_surface_temperature_min_before_30028',\n",
       " 'soil_surface_temperature_max_before_30028',\n",
       " 'soil_surface_max_temperature_30028',\n",
       " 'air_temperature_30028',\n",
       " 'air_temperature_wet_bulb_30028',\n",
       " 'air_temperature_min_alco_temperature_30028',\n",
       " 'air_temperature_min_before_30028',\n",
       " 'air_temperature_max_before_30028',\n",
       " 'air_max_temperature_30028',\n",
       " 'water_vapour_partial_pressure_30028',\n",
       " 'relative_humidity_30028',\n",
       " 'vapour_pressure_deficit_30028',\n",
       " 'dew_point_temperature_30028',\n",
       " 'pressure_30028',\n",
       " 'pressure_sea_level_30028',\n",
       " 'barometric_tendency_characteristic_30028',\n",
       " 'barometric_tendency_30028',\n",
       " 'horizontal_visibility_30219',\n",
       " 'cloud_amount_total_30219',\n",
       " 'cloud_amount_low_level_30219',\n",
       " 'cloud_form_high_level_30219',\n",
       " 'cloud_form_middle_level_30219',\n",
       " 'cloud_form_vertical_develop_30219',\n",
       " 'cloud_form_strat_stratocum_30219',\n",
       " 'cloud_form_strat_rain_30219',\n",
       " 'cloud_base_altitude_30219',\n",
       " 'cloud_below_station_30219',\n",
       " 'soil_surface_condition_30219',\n",
       " 'weather_before_30219',\n",
       " 'weather_30219',\n",
       " 'wind_direction_30219',\n",
       " 'wind_speed_aver_30219',\n",
       " 'wind_speed_max_30219',\n",
       " 'precipitation_30219',\n",
       " 'soil_surface_temperature_30219',\n",
       " 'soil_surface_alco_temperature_30219',\n",
       " 'soil_surface_temperature_min_before_30219',\n",
       " 'soil_surface_temperature_max_before_30219',\n",
       " 'soil_surface_max_temperature_30219',\n",
       " 'air_temperature_30219',\n",
       " 'air_temperature_wet_bulb_30219',\n",
       " 'air_temperature_min_alco_temperature_30219',\n",
       " 'air_temperature_min_before_30219',\n",
       " 'air_temperature_max_before_30219',\n",
       " 'air_max_temperature_30219',\n",
       " 'water_vapour_partial_pressure_30219',\n",
       " 'relative_humidity_30219',\n",
       " 'vapour_pressure_deficit_30219',\n",
       " 'dew_point_temperature_30219',\n",
       " 'pressure_30219',\n",
       " 'pressure_sea_level_30219',\n",
       " 'barometric_tendency_characteristic_30219',\n",
       " 'barometric_tendency_30219',\n",
       " 'horizontal_visibility_30328',\n",
       " 'cloud_amount_total_30328',\n",
       " 'cloud_amount_low_level_30328',\n",
       " 'cloud_form_high_level_30328',\n",
       " 'cloud_form_middle_level_30328',\n",
       " 'cloud_form_vertical_develop_30328',\n",
       " 'cloud_form_strat_stratocum_30328',\n",
       " 'cloud_form_strat_rain_30328',\n",
       " 'cloud_base_altitude_30328',\n",
       " 'cloud_below_station_30328',\n",
       " 'soil_surface_condition_30328',\n",
       " 'weather_before_30328',\n",
       " 'weather_30328',\n",
       " 'wind_direction_30328',\n",
       " 'wind_speed_aver_30328',\n",
       " 'wind_speed_max_30328',\n",
       " 'precipitation_30328',\n",
       " 'soil_surface_temperature_30328',\n",
       " 'soil_surface_alco_temperature_30328',\n",
       " 'soil_surface_temperature_min_before_30328',\n",
       " 'soil_surface_temperature_max_before_30328',\n",
       " 'soil_surface_max_temperature_30328',\n",
       " 'air_temperature_30328',\n",
       " 'air_temperature_wet_bulb_30328',\n",
       " 'air_temperature_min_alco_temperature_30328',\n",
       " 'air_temperature_min_before_30328',\n",
       " 'air_temperature_max_before_30328',\n",
       " 'air_max_temperature_30328',\n",
       " 'water_vapour_partial_pressure_30328',\n",
       " 'relative_humidity_30328',\n",
       " 'vapour_pressure_deficit_30328',\n",
       " 'dew_point_temperature_30328',\n",
       " 'pressure_30328',\n",
       " 'pressure_sea_level_30328',\n",
       " 'barometric_tendency_characteristic_30328',\n",
       " 'barometric_tendency_30328',\n",
       " 'horizontal_visibility_30337',\n",
       " 'cloud_amount_total_30337',\n",
       " 'cloud_amount_low_level_30337',\n",
       " 'cloud_form_high_level_30337',\n",
       " 'cloud_form_middle_level_30337',\n",
       " 'cloud_form_vertical_develop_30337',\n",
       " 'cloud_form_strat_stratocum_30337',\n",
       " 'cloud_form_strat_rain_30337',\n",
       " 'cloud_base_altitude_30337',\n",
       " 'cloud_below_station_30337',\n",
       " 'soil_surface_condition_30337',\n",
       " 'weather_before_30337',\n",
       " 'weather_30337',\n",
       " 'wind_direction_30337',\n",
       " 'wind_speed_aver_30337',\n",
       " 'wind_speed_max_30337',\n",
       " 'precipitation_30337',\n",
       " 'soil_surface_temperature_30337',\n",
       " 'soil_surface_alco_temperature_30337',\n",
       " 'soil_surface_temperature_min_before_30337',\n",
       " 'soil_surface_temperature_max_before_30337',\n",
       " 'soil_surface_max_temperature_30337',\n",
       " 'air_temperature_30337',\n",
       " 'air_temperature_wet_bulb_30337',\n",
       " 'air_temperature_min_alco_temperature_30337',\n",
       " 'air_temperature_min_before_30337',\n",
       " 'air_temperature_max_before_30337',\n",
       " 'air_max_temperature_30337',\n",
       " 'water_vapour_partial_pressure_30337',\n",
       " 'relative_humidity_30337',\n",
       " 'vapour_pressure_deficit_30337',\n",
       " 'dew_point_temperature_30337',\n",
       " 'pressure_30337',\n",
       " 'pressure_sea_level_30337',\n",
       " 'barometric_tendency_characteristic_30337',\n",
       " 'barometric_tendency_30337',\n",
       " 'horizontal_visibility_30433',\n",
       " 'cloud_amount_total_30433',\n",
       " 'cloud_amount_low_level_30433',\n",
       " 'cloud_form_high_level_30433',\n",
       " 'cloud_form_middle_level_30433',\n",
       " 'cloud_form_vertical_develop_30433',\n",
       " 'cloud_form_strat_stratocum_30433',\n",
       " 'cloud_form_strat_rain_30433',\n",
       " 'cloud_base_altitude_30433',\n",
       " 'cloud_below_station_30433',\n",
       " 'soil_surface_condition_30433',\n",
       " 'weather_before_30433',\n",
       " 'weather_30433',\n",
       " 'wind_direction_30433',\n",
       " 'wind_speed_aver_30433',\n",
       " 'wind_speed_max_30433',\n",
       " 'precipitation_30433',\n",
       " 'soil_surface_temperature_30433',\n",
       " 'soil_surface_alco_temperature_30433',\n",
       " 'soil_surface_temperature_min_before_30433',\n",
       " 'soil_surface_temperature_max_before_30433',\n",
       " 'soil_surface_max_temperature_30433',\n",
       " 'air_temperature_30433',\n",
       " 'air_temperature_wet_bulb_30433',\n",
       " 'air_temperature_min_alco_temperature_30433',\n",
       " 'air_temperature_min_before_30433',\n",
       " 'air_temperature_max_before_30433',\n",
       " 'air_max_temperature_30433',\n",
       " 'water_vapour_partial_pressure_30433',\n",
       " 'relative_humidity_30433',\n",
       " 'vapour_pressure_deficit_30433',\n",
       " 'dew_point_temperature_30433',\n",
       " 'pressure_30433',\n",
       " 'pressure_sea_level_30433',\n",
       " 'barometric_tendency_characteristic_30433',\n",
       " 'barometric_tendency_30433',\n",
       " 'horizontal_visibility_30230',\n",
       " 'cloud_amount_total_30230',\n",
       " 'cloud_amount_low_level_30230',\n",
       " 'cloud_form_high_level_30230',\n",
       " 'cloud_form_middle_level_30230',\n",
       " 'cloud_form_vertical_develop_30230',\n",
       " 'cloud_form_strat_stratocum_30230',\n",
       " 'cloud_form_strat_rain_30230',\n",
       " 'cloud_base_altitude_30230',\n",
       " 'cloud_below_station_30230',\n",
       " 'soil_surface_condition_30230',\n",
       " 'weather_before_30230',\n",
       " 'weather_30230',\n",
       " 'wind_direction_30230',\n",
       " 'wind_speed_aver_30230',\n",
       " 'wind_speed_max_30230',\n",
       " 'precipitation_30230',\n",
       " 'soil_surface_temperature_30230',\n",
       " 'soil_surface_alco_temperature_30230',\n",
       " 'soil_surface_temperature_min_before_30230',\n",
       " 'soil_surface_temperature_max_before_30230',\n",
       " 'soil_surface_max_temperature_30230',\n",
       " 'air_temperature_30230',\n",
       " 'air_temperature_wet_bulb_30230',\n",
       " 'air_temperature_min_alco_temperature_30230',\n",
       " 'air_temperature_min_before_30230',\n",
       " 'air_temperature_max_before_30230',\n",
       " 'air_max_temperature_30230',\n",
       " 'water_vapour_partial_pressure_30230',\n",
       " 'relative_humidity_30230',\n",
       " 'vapour_pressure_deficit_30230',\n",
       " 'dew_point_temperature_30230',\n",
       " 'pressure_30230',\n",
       " 'pressure_sea_level_30230',\n",
       " 'barometric_tendency_characteristic_30230',\n",
       " 'barometric_tendency_30230',\n",
       " 'delta_stage_max_1',\n",
       " 'delta_stage_max_2',\n",
       " 'delta_stage_max_3',\n",
       " 'delta_stage_max_4',\n",
       " 'delta_stage_max_5',\n",
       " 'delta_stage_max_6',\n",
       " 'delta_stage_max_7']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "expressed-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = list(data.filter(regex='water_code').columns)\n",
    "target = list(data.filter(regex='delta_stage_max').columns)\n",
    "X = data.drop(['station_id','date','year']+wc+target,axis=1).to_numpy()\n",
    "# X = data.drop(['station_id','date','delta_stage_max']+wc,axis=1).to_numpy()\n",
    "y = data.delta_stage_max.to_numpy()\n",
    "y1 = data.delta_stage_max_1.to_numpy()\n",
    "y2 = data.delta_stage_max_2.to_numpy()\n",
    "y3 = data.delta_stage_max_3.to_numpy()\n",
    "y4 = data.delta_stage_max_4.to_numpy()\n",
    "y5 = data.delta_stage_max_5.to_numpy()\n",
    "y6 = data.delta_stage_max_6.to_numpy()\n",
    "y7 = data.delta_stage_max_7.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, train_size=0.2, random_state=13)\n",
    "_, _, y1_train, y1_test = train_test_split(X, y1, shuffle=False, train_size=0.2, random_state=13)\n",
    "_, _, y2_train, y2_test = train_test_split(X, y2, shuffle=False, train_size=0.2, random_state=13)\n",
    "_, _, y3_train, y3_test = train_test_split(X, y3, shuffle=False, train_size=0.2, random_state=13)\n",
    "_, _, y4_train, y4_test = train_test_split(X, y4, shuffle=False, train_size=0.2, random_state=13)\n",
    "_, _, y5_train, y5_test = train_test_split(X, y5, shuffle=False, train_size=0.2, random_state=13)\n",
    "_, _, y6_train, y6_test = train_test_split(X, y6, shuffle=False, train_size=0.2, random_state=13)\n",
    "_, _, y7_train, y7_test = train_test_split(X, y7, shuffle=False, train_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "proof-champagne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3019"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kirensk_dict['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecological-joseph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_3019\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1835456\ttest: 12.4127636\tbest: 12.4127636 (0)\ttotal: 10.5ms\tremaining: 31.6s\n",
      "2999:\tlearn: 1.0927607\ttest: 12.1775483\tbest: 11.9059295 (344)\ttotal: 17.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.90592953\n",
      "bestIteration = 344\n",
      "\n",
      "Shrink model to first 345 iterations.\n",
      "model_3019_1\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1620032\ttest: 12.3973327\tbest: 12.3973327 (0)\ttotal: 7.13ms\tremaining: 21.4s\n",
      "2999:\tlearn: 0.9882874\ttest: 12.1722095\tbest: 11.8609571 (79)\ttotal: 17.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.86095712\n",
      "bestIteration = 79\n",
      "\n",
      "Shrink model to first 80 iterations.\n",
      "model_3019_2\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1628154\ttest: 12.4020443\tbest: 12.4020443 (0)\ttotal: 6.54ms\tremaining: 19.6s\n",
      "2999:\tlearn: 1.0008010\ttest: 11.8199908\tbest: 11.5947957 (270)\ttotal: 17.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.59479568\n",
      "bestIteration = 270\n",
      "\n",
      "Shrink model to first 271 iterations.\n",
      "model_3019_3\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1320205\ttest: 12.3916551\tbest: 12.3916551 (0)\ttotal: 6ms\tremaining: 18s\n",
      "2999:\tlearn: 1.0081175\ttest: 11.7743809\tbest: 11.5385340 (238)\ttotal: 17.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.538534\n",
      "bestIteration = 238\n",
      "\n",
      "Shrink model to first 239 iterations.\n",
      "model_3019_4\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1479352\ttest: 12.4019577\tbest: 12.4019577 (0)\ttotal: 6.08ms\tremaining: 18.2s\n",
      "2999:\tlearn: 1.0590080\ttest: 11.8101526\tbest: 11.5225859 (238)\ttotal: 17.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.5225859\n",
      "bestIteration = 238\n",
      "\n",
      "Shrink model to first 239 iterations.\n",
      "model_3019_5\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1352858\ttest: 12.3968752\tbest: 12.3968752 (0)\ttotal: 5.97ms\tremaining: 17.9s\n",
      "2999:\tlearn: 1.0829207\ttest: 11.9964424\tbest: 11.7205953 (221)\ttotal: 17.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.72059529\n",
      "bestIteration = 221\n",
      "\n",
      "Shrink model to first 222 iterations.\n",
      "model_3019_6\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1356220\ttest: 12.4079395\tbest: 12.4079395 (0)\ttotal: 5.98ms\tremaining: 17.9s\n",
      "2999:\tlearn: 1.0732155\ttest: 12.1819150\tbest: 11.8955730 (308)\ttotal: 17.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.89557296\n",
      "bestIteration = 308\n",
      "\n",
      "Shrink model to first 309 iterations.\n",
      "model_3019_7\n",
      "Learning rate set to 0.027245\n",
      "0:\tlearn: 12.1482669\ttest: 12.4141218\tbest: 12.4141218 (0)\ttotal: 6.07ms\tremaining: 18.2s\n",
      "2999:\tlearn: 1.1063867\ttest: 12.5021456\tbest: 12.0410642 (189)\ttotal: 17.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.04106418\n",
      "bestIteration = 189\n",
      "\n",
      "Shrink model to first 190 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f7a34e3c6d8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'iterations': 3000,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': 13,\n",
    "    'use_best_model': True\n",
    "}\n",
    "\n",
    "print('model_3019')\n",
    "model_3019 = catboost.CatBoostRegressor(**params)\n",
    "model_3019.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    verbose=3000\n",
    ")\n",
    "print('model_3019_1')\n",
    "model_3019_1 = catboost.CatBoostRegressor(**params)\n",
    "model_3019_1.fit(\n",
    "    X_train, y1_train,\n",
    "    eval_set=(X_test, y1_test),\n",
    "    verbose=3000\n",
    ")\n",
    "print('model_3019_2')\n",
    "model_3019_2 = catboost.CatBoostRegressor(**params)\n",
    "model_3019_2.fit(\n",
    "    X_train, y2_train,\n",
    "    eval_set=(X_test, y2_test), \n",
    "    verbose=3000\n",
    ")\n",
    "print('model_3019_3')\n",
    "model_3019_3 = catboost.CatBoostRegressor(**params)\n",
    "model_3019_3.fit(\n",
    "    X_train, y3_train,\n",
    "    eval_set=(X_test, y3_test),  \n",
    "    verbose=3000\n",
    ")\n",
    "print('model_3019_4')\n",
    "model_3019_4 = catboost.CatBoostRegressor(**params)\n",
    "model_3019_4.fit(\n",
    "    X_train, y4_train,\n",
    "    eval_set=(X_test, y4_test),  \n",
    "    verbose=3000\n",
    ")\n",
    "print('model_3019_5')\n",
    "model_3019_5 = catboost.CatBoostRegressor(**params)\n",
    "model_3019_5.fit(\n",
    "    X_train, y5_train,\n",
    "    eval_set=(X_test, y5_test),  \n",
    "    verbose=3000\n",
    ")\n",
    "print('model_3019_6')\n",
    "model_3019_6 = catboost.CatBoostRegressor(**params)\n",
    "model_3019_6.fit(\n",
    "    X_train, y6_train,\n",
    "    eval_set=(X_test, y6_test),  \n",
    "    verbose=3000\n",
    ")\n",
    "print('model_3019_7')\n",
    "model_3019_7 = catboost.CatBoostRegressor(**params)\n",
    "model_3019_7.fit(\n",
    "    X_train, y7_train,\n",
    "    eval_set=(X_test, y7_test),  \n",
    "    verbose=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "engaged-retro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3019"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kirensk_dict['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "married-astrology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678782332775705"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = mean_squared_error(y_test, model_3019.predict(X_test))/kirensk_dict['std_sq']\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-courage",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "certain-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gydro_raw (2482, 15)\n",
      "meteo_raw (46424, 94)\n"
     ]
    }
   ],
   "source": [
    "# собрать датасет\n",
    "dirs = os.listdir('../data/raw/test_data')\n",
    "files = os.listdir('../data/raw/test_data/2_track_cp3')\n",
    "names = ['extra_train.csv','extra_meteo_3hours.csv']\n",
    "\n",
    "gydro_raw = pd.DataFrame()\n",
    "meteo_raw = pd.DataFrame()\n",
    "\n",
    "for d in dirs:\n",
    "    for f in files:\n",
    "        if f in names:\n",
    "            if f == 'extra_train.csv':\n",
    "                gydro_raw = pd.concat([\n",
    "                    gydro_raw, \n",
    "                    pd.read_csv(f'../data/raw/test_data/{d}/{f}', parse_dates=['date']),\n",
    "                ])\n",
    "            if f == 'extra_meteo_3hours.csv':\n",
    "                meteo_raw = pd.concat([\n",
    "                    meteo_raw,\n",
    "                    pd.read_csv(f'../data/raw/test_data/{d}/{f}', parse_dates=['date_local']),\n",
    "                ])\n",
    "print('gydro_raw', gydro_raw.shape)\n",
    "print('meteo_raw', meteo_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "polish-illness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gydro_df (140, 33)\n",
      "meteo_df (154, 218)\n",
      "test_data (140, 250)\n",
      "NaNs 0\n",
      "test_data (140, 250)\n"
     ]
    }
   ],
   "source": [
    "# Киренск\n",
    "gydro_df = make_gydro_df(gydro_raw, kirensk_dict)\n",
    "print('gydro_df', gydro_df.shape)\n",
    "\n",
    "meteo_df = make_meteo_df(meteo_raw, kirensk_dict['meteo_st'])\n",
    "print('meteo_df', meteo_df.shape)\n",
    "\n",
    "test_data = pd.merge(gydro_df, meteo_df.rename(columns={'date_local': 'date'}), how='left', on='date')\n",
    "print('test_data',test_data.shape)\n",
    "\n",
    "test_data.fillna(-777, inplace=True)\n",
    "print('NaNs', sum(test_data.isna().sum()))\n",
    "\n",
    "# test_data['delta_stage_max_1'] = test_data.delta_stage_max.shift(1)\n",
    "# test_data['delta_stage_max_2'] = test_data.delta_stage_max.shift(2)\n",
    "# test_data['delta_stage_max_3'] = test_data.delta_stage_max.shift(3)\n",
    "# test_data['delta_stage_max_4'] = test_data.delta_stage_max.shift(4)\n",
    "# test_data['delta_stage_max_5'] = test_data.delta_stage_max.shift(5)\n",
    "# test_data['delta_stage_max_6'] = test_data.delta_stage_max.shift(6)\n",
    "# test_data['delta_stage_max_7'] = test_data.delta_stage_max.shift(7)\n",
    "\n",
    "# test_data.dropna(inplace=True)\n",
    "print('test_data', test_data.shape)\n",
    "\n",
    "with open(f\"{kirensk_dict['name']}_test_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "related-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = list(test_data.filter(regex='water_code').columns)\n",
    "X = test_data.drop(['station_id','date','year','delta_stage_max']+wc,axis=1).to_numpy()\n",
    "y = test_data.delta_stage_max.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "assigned-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.652152644785904"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = mean_squared_error(y, model_3019.predict(X))/kirensk_dict['std_sq']\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "awful-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>132</td>\n",
       "      <td>1993-05-12</td>\n",
       "      <td>6.750468</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>1993-05-13</td>\n",
       "      <td>4.332843</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>1993-05-14</td>\n",
       "      <td>12.405399</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>1993-05-15</td>\n",
       "      <td>9.990483</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>1993-05-16</td>\n",
       "      <td>5.270911</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2013</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>2013-04-23</td>\n",
       "      <td>3.357035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2013</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>2.630841</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2013</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>2013-04-25</td>\n",
       "      <td>3.586223</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2013</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>2013-04-26</td>\n",
       "      <td>11.438807</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2013</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>2013-04-27</td>\n",
       "      <td>3.592313</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  station_id  month  day       date  delta_stage_max     y\n",
       "0    1993        3019      5  132 1993-05-12         6.750468   3.0\n",
       "1    1993        3019      5  133 1993-05-13         4.332843  -2.0\n",
       "2    1993        3019      5  134 1993-05-14        12.405399  -9.0\n",
       "3    1993        3019      5  135 1993-05-15         9.990483 -11.0\n",
       "4    1993        3019      5  136 1993-05-16         5.270911  -2.0\n",
       "..    ...         ...    ...  ...        ...              ...   ...\n",
       "135  2013        3019      4  113 2013-04-23         3.357035   0.0\n",
       "136  2013        3019      4  114 2013-04-24         2.630841   3.0\n",
       "137  2013        3019      4  115 2013-04-25         3.586223   3.0\n",
       "138  2013        3019      4  116 2013-04-26        11.438807   5.0\n",
       "139  2013        3019      4  117 2013-04-27         3.592313   4.0\n",
       "\n",
       "[140 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# формат для сабмита\n",
    "pd.DataFrame({\n",
    "    'year': test_data.year,\n",
    "    'station_id': test_data.station_id,\n",
    "    'month': test_data.month,\n",
    "    'day': test_data.day,\n",
    "    'date': test_data.date,\n",
    "    'delta_stage_max':  model_3019.predict(X),\n",
    "    'y': test_data.delta_stage_max\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-bangladesh",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-single",
   "metadata": {},
   "source": [
    "### Train v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "running-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gydro_raw (4071, 15)\n",
      "meteo_raw (60880, 94)\n"
     ]
    }
   ],
   "source": [
    "# concat extra data\n",
    "\n",
    "dirs = os.listdir('../data/raw/test_data')\n",
    "files = os.listdir('../data/raw/test_data/2_track_cp4')\n",
    "names = ['extra_train.csv','extra_meteo_3hours.csv']\n",
    "\n",
    "gydro_extra = pd.DataFrame()\n",
    "meteo_extra = pd.DataFrame()\n",
    "\n",
    "for d in dirs:\n",
    "    for f in files:\n",
    "        if f in names:\n",
    "            if f == 'extra_train.csv':\n",
    "                gydro_extra = pd.concat([\n",
    "                    gydro_extra, \n",
    "                    pd.read_csv(f'../data/raw/test_data/{d}/{f}', parse_dates=['date']),\n",
    "                ])\n",
    "            if f == 'extra_meteo_3hours.csv':\n",
    "                meteo_extra = pd.concat([\n",
    "                    meteo_extra,\n",
    "                    pd.read_csv(f'../data/raw/test_data/{d}/{f}', parse_dates=['date_local']),\n",
    "                ])\n",
    "print('gydro_raw', gydro_extra.shape)\n",
    "print('meteo_raw', meteo_extra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "manufactured-japanese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313538, 15)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединим все имеющиеся гидлорогические данные\n",
    "gydro_raw = pd.concat([\n",
    "    pd.read_csv(f'{RAWDATADIR}/track_2_package/train.csv', parse_dates=['date']),\n",
    "    pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date']),\n",
    "    gydro_extra\n",
    "])\n",
    "\n",
    "gydro_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "precious-shaft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3727432, 94)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединим все имеющиеся метеорологические данные\n",
    "meteo_raw = pd.concat([\n",
    "    pd.read_csv(f'{RAWDATADIR}/track_2_package/meteo_3hours.csv', parse_dates=['date_local']),\n",
    "    meteo_extra\n",
    "])\n",
    "\n",
    "meteo_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "impaired-hepatitis",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Киренск\n",
      "gydro_df (12024, 33)\n",
      "meteo_df (12512, 218)\n",
      "data (12024, 250)\n",
      "NaNs 0\n",
      "data (12024, 250)\n",
      "len(test_dates)= 224\n",
      "train_data (11793, 250)\n",
      "test_data (224, 250)\n",
      "тренировка модели\n",
      "model_3019\n",
      "Learning rate set to 0.073455\n",
      "0:\tlearn: 12.8559841\ttest: 3.1508944\tbest: 3.1508944 (0)\ttotal: 69.3ms\tremaining: 1m 9s\n",
      "999:\tlearn: 5.3496588\ttest: 3.0336315\tbest: 2.9070190 (9)\ttotal: 7.61s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.907019043\n",
      "bestIteration = 9\n",
      "\n",
      "Shrink model to first 10 iterations.\n",
      "Витим\n",
      "gydro_df (17510, 96)\n",
      "meteo_df (12512, 362)\n",
      "data (17510, 457)\n",
      "NaNs 0\n",
      "data (17510, 457)\n",
      "len(test_dates)= 252\n",
      "train_data (12337, 457)\n",
      "test_data (5166, 457)\n",
      "тренировка модели\n",
      "model_3027\n",
      "Learning rate set to 0.074084\n",
      "0:\tlearn: 33.4515961\ttest: 5.0985888\tbest: 5.0985888 (0)\ttotal: 19ms\tremaining: 18.9s\n",
      "999:\tlearn: 13.3164299\ttest: 21.3068052\tbest: 1.8286184 (43)\ttotal: 13.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.828618368\n",
      "bestIteration = 43\n",
      "\n",
      "Shrink model to first 44 iterations.\n",
      "Пеледуй\n",
      "gydro_df (17601, 96)\n",
      "meteo_df (12512, 362)\n",
      "data (17601, 457)\n",
      "NaNs 0\n",
      "data (17601, 457)\n",
      "len(test_dates)= 245\n",
      "train_data (12435, 457)\n",
      "test_data (5159, 457)\n",
      "тренировка модели\n",
      "model_3028\n",
      "Learning rate set to 0.074195\n",
      "0:\tlearn: 35.1868787\ttest: 7.1126722\tbest: 7.1126722 (0)\ttotal: 15.2ms\tremaining: 15.2s\n",
      "999:\tlearn: 13.8403552\ttest: 2.6441263\tbest: 1.7686108 (679)\ttotal: 13.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.768610804\n",
      "bestIteration = 679\n",
      "\n",
      "Shrink model to first 680 iterations.\n",
      "Крестовский Лесоучасток\n",
      "gydro_df (17662, 96)\n",
      "meteo_df (12512, 362)\n",
      "data (17662, 457)\n",
      "NaNs 0\n",
      "data (17662, 457)\n",
      "len(test_dates)= 252\n",
      "train_data (12489, 457)\n",
      "test_data (5166, 457)\n",
      "тренировка модели\n",
      "model_3029\n",
      "Learning rate set to 0.074256\n",
      "0:\tlearn: 36.1036623\ttest: 9.4927395\tbest: 9.4927395 (0)\ttotal: 15.5ms\tremaining: 15.5s\n",
      "999:\tlearn: 13.8452411\ttest: 40.1465149\tbest: 3.8383683 (308)\ttotal: 13.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 3.838368327\n",
      "bestIteration = 308\n",
      "\n",
      "Shrink model to first 309 iterations.\n",
      "Ленск\n",
      "gydro_df (17662, 96)\n",
      "meteo_df (12512, 362)\n",
      "data (17662, 457)\n",
      "NaNs 0\n",
      "data (17662, 457)\n",
      "len(test_dates)= 252\n",
      "train_data (12489, 457)\n",
      "test_data (5166, 457)\n",
      "тренировка модели\n",
      "model_3030\n",
      "Learning rate set to 0.074256\n",
      "0:\tlearn: 39.6730299\ttest: 11.7565232\tbest: 11.7565232 (0)\ttotal: 16.3ms\tremaining: 16.3s\n",
      "999:\tlearn: 12.2580305\ttest: 17.7502557\tbest: 5.3162965 (779)\ttotal: 13.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 5.316296492\n",
      "bestIteration = 779\n",
      "\n",
      "Shrink model to first 780 iterations.\n",
      "Олекминск\n",
      "gydro_df (12748, 60)\n",
      "meteo_df (12572, 434)\n",
      "data (12748, 493)\n",
      "NaNs 0\n",
      "data (12748, 493)\n",
      "len(test_dates)= 252\n",
      "train_data (12489, 493)\n",
      "test_data (252, 493)\n",
      "тренировка модели\n",
      "model_3035\n",
      "Learning rate set to 0.074256\n",
      "0:\tlearn: 26.1084602\ttest: 7.9051728\tbest: 7.9051728 (0)\ttotal: 17.5ms\tremaining: 17.5s\n",
      "999:\tlearn: 9.0229231\ttest: 6.5676958\tbest: 5.9881404 (978)\ttotal: 14.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 5.988140438\n",
      "bestIteration = 978\n",
      "\n",
      "Shrink model to first 979 iterations.\n",
      "Покровск\n",
      "gydro_df (13126, 51)\n",
      "meteo_df (12512, 326)\n",
      "data (13126, 376)\n",
      "NaNs 0\n",
      "data (13126, 376)\n",
      "len(test_dates)= 252\n",
      "train_data (12489, 376)\n",
      "test_data (630, 376)\n",
      "тренировка модели\n",
      "model_3041\n",
      "Learning rate set to 0.074256\n",
      "0:\tlearn: 19.9817201\ttest: 7.6075822\tbest: 7.6075822 (0)\ttotal: 15.2ms\tremaining: 15.2s\n",
      "999:\tlearn: 7.2616167\ttest: 15.6370867\tbest: 3.3073079 (9)\ttotal: 11.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 3.307307879\n",
      "bestIteration = 9\n",
      "\n",
      "Shrink model to first 10 iterations.\n",
      "Якутск\n",
      "gydro_df (13126, 51)\n",
      "meteo_df (12512, 326)\n",
      "data (13126, 376)\n",
      "NaNs 0\n",
      "data (13126, 376)\n",
      "len(test_dates)= 252\n",
      "train_data (12489, 376)\n",
      "test_data (630, 376)\n",
      "тренировка модели\n",
      "model_3045\n",
      "Learning rate set to 0.074256\n",
      "0:\tlearn: 22.7506598\ttest: 8.8301649\tbest: 8.8301649 (0)\ttotal: 13.9ms\tremaining: 13.9s\n",
      "999:\tlearn: 7.5076003\ttest: 18.2148900\tbest: 3.8740339 (124)\ttotal: 10.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 3.874033917\n",
      "bestIteration = 124\n",
      "\n",
      "Shrink model to first 125 iterations.\n",
      "Батамай\n",
      "gydro_df (12761, 33)\n",
      "meteo_df (12512, 326)\n",
      "data (12761, 358)\n",
      "NaNs 0\n",
      "data (12761, 358)\n",
      "len(test_dates)= 252\n",
      "train_data (12124, 358)\n",
      "test_data (630, 358)\n",
      "тренировка модели\n",
      "model_3230\n",
      "Learning rate set to 0.073841\n",
      "0:\tlearn: 21.0710490\ttest: 9.6045834\tbest: 9.6045834 (0)\ttotal: 11.8ms\tremaining: 11.7s\n",
      "999:\tlearn: 7.0135081\ttest: 8.3828131\tbest: 2.9383866 (128)\ttotal: 10.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.938386636\n",
      "bestIteration = 128\n",
      "\n",
      "Shrink model to first 129 iterations.\n",
      "Сангар\n",
      "gydro_df (13034, 33)\n",
      "meteo_df (12512, 326)\n",
      "data (13034, 358)\n",
      "NaNs 0\n",
      "data (13034, 358)\n",
      "len(test_dates)= 252\n",
      "train_data (12397, 358)\n",
      "test_data (630, 358)\n",
      "тренировка модели\n",
      "model_3050\n",
      "Learning rate set to 0.074152\n",
      "0:\tlearn: 23.1227525\ttest: 5.3330489\tbest: 5.3330489 (0)\ttotal: 12.2ms\tremaining: 12.2s\n",
      "999:\tlearn: 8.2515186\ttest: 7.9489415\tbest: 1.9599924 (120)\ttotal: 10.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.959992369\n",
      "bestIteration = 120\n",
      "\n",
      "Shrink model to first 121 iterations.\n"
     ]
    }
   ],
   "source": [
    "# подготовим датасеты для обучения и теста\n",
    "verbose = True\n",
    "test = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "\n",
    "for st_dict in target_stations:\n",
    "    print(st_dict['name']) \n",
    "    gydro_df = make_gydro_df(gydro_raw, st_dict)\n",
    "    if verbose: print('gydro_df', gydro_df.shape)\n",
    "\n",
    "    meteo_df = make_meteo_df(meteo_raw, st_dict['meteo_st'])\n",
    "    if verbose: print('meteo_df', meteo_df.shape)\n",
    "\n",
    "    data = pd.merge(gydro_df, meteo_df.rename(columns={'date_local': 'date'}), how='left', on='date')\n",
    "    if verbose: print('data',data.shape)\n",
    "\n",
    "    data.fillna(-777, inplace=True)\n",
    "    if verbose: print('NaNs', sum(data.isna().sum()))\n",
    "    if verbose: print('data', data.shape)\n",
    "    \n",
    "    with open(f\"datasetsv2/{st_dict['id']}_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "    shift_features = data.drop('delta_stage_max',axis=1).columns\n",
    "    data[shift_features] = data[shift_features].shift(7)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    test_dates = test[test.station_id==st_dict['id']].date.values\n",
    "    if verbose: print('len(test_dates)=', len(test_dates))\n",
    "    test_mask = data.date.isin(test_dates)\n",
    "    train_data = data[~test_mask]\n",
    "    if verbose: print('train_data', train_data.shape)\n",
    "    test_data = data[test_mask]\n",
    "    if verbose: print('test_data', test_data.shape)\n",
    "\n",
    "    with open(f\"datasetsv2/{st_dict['id']}_train_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(train_data, f)\n",
    "    with open(f\"datasetsv2/{st_dict['id']}_test_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(test_data, f)\n",
    "    \n",
    "    \n",
    "    wcode = list(train_data.filter(regex='water_code').columns)\n",
    "    X_train = train_data.drop(['station_id','date','year','delta_stage_max'] + wcode,axis=1).to_numpy()\n",
    "    y_train = train_data.delta_stage_max.to_numpy()\n",
    "    X_test = test_data.drop(['station_id','date','year','delta_stage_max'] + wcode,axis=1).to_numpy()\n",
    "    y_test = test_data.delta_stage_max.to_numpy()\n",
    "    \n",
    "    # тренировка модели\n",
    "    print('тренировка модели')\n",
    "    params = {\n",
    "        'iterations': 1000,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': 13,\n",
    "        'use_best_model': True\n",
    "    }\n",
    "    model_name = f\"model_{st_dict['id']}\"\n",
    "    print(model_name)\n",
    "    model = catboost.CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_test, y_test),\n",
    "        verbose=1000\n",
    "    )\n",
    "    with open(f'modelsv2/{model_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-synthetic",
   "metadata": {},
   "source": [
    "### Submit v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "apparent-interference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stage_avg</th>\n",
       "      <th>stage_min</th>\n",
       "      <th>stage_max</th>\n",
       "      <th>temp</th>\n",
       "      <th>water_code</th>\n",
       "      <th>ice_thickness</th>\n",
       "      <th>snow_height</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>air_temperature_max_before_24763</th>\n",
       "      <th>air_max_temperature_24763</th>\n",
       "      <th>water_vapour_partial_pressure_24763</th>\n",
       "      <th>relative_humidity_24763</th>\n",
       "      <th>vapour_pressure_deficit_24763</th>\n",
       "      <th>dew_point_temperature_24763</th>\n",
       "      <th>pressure_24763</th>\n",
       "      <th>pressure_sea_level_24763</th>\n",
       "      <th>barometric_tendency_characteristic_24763</th>\n",
       "      <th>barometric_tendency_24763</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12194</th>\n",
       "      <td>3050.0</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>149.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12195</th>\n",
       "      <td>3050.0</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>149.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>3050.0</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>149.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197</th>\n",
       "      <td>3050.0</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>149.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12198</th>\n",
       "      <td>3050.0</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>149.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>-777.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 358 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_id       date  stage_avg  stage_min  stage_max  temp  \\\n",
       "12194      3050.0 1993-04-21       82.0       82.0       82.0   0.0   \n",
       "12195      3050.0 1993-04-22       82.0       82.0       82.0   0.0   \n",
       "12196      3050.0 1993-04-23       82.0       82.0       82.0   0.0   \n",
       "12197      3050.0 1993-04-24       82.0       82.0       82.0   0.0   \n",
       "12198      3050.0 1993-04-25       82.0       82.0       82.0   0.0   \n",
       "\n",
       "      water_code  ice_thickness  snow_height  place  ...  \\\n",
       "12194        nan          149.0         20.0    0.0  ...   \n",
       "12195        nan          149.0         20.0    0.0  ...   \n",
       "12196        nan          149.0         20.0    0.0  ...   \n",
       "12197        nan          149.0         20.0    0.0  ...   \n",
       "12198        nan          149.0         20.0    0.0  ...   \n",
       "\n",
       "       air_temperature_max_before_24763  air_max_temperature_24763  \\\n",
       "12194                            -777.0                     -777.0   \n",
       "12195                            -777.0                     -777.0   \n",
       "12196                            -777.0                     -777.0   \n",
       "12197                            -777.0                     -777.0   \n",
       "12198                            -777.0                     -777.0   \n",
       "\n",
       "       water_vapour_partial_pressure_24763  relative_humidity_24763  \\\n",
       "12194                               -777.0                   -777.0   \n",
       "12195                               -777.0                   -777.0   \n",
       "12196                               -777.0                   -777.0   \n",
       "12197                               -777.0                   -777.0   \n",
       "12198                               -777.0                   -777.0   \n",
       "\n",
       "       vapour_pressure_deficit_24763  dew_point_temperature_24763  \\\n",
       "12194                         -777.0                       -777.0   \n",
       "12195                         -777.0                       -777.0   \n",
       "12196                         -777.0                       -777.0   \n",
       "12197                         -777.0                       -777.0   \n",
       "12198                         -777.0                       -777.0   \n",
       "\n",
       "       pressure_24763  pressure_sea_level_24763  \\\n",
       "12194          -777.0                    -777.0   \n",
       "12195          -777.0                    -777.0   \n",
       "12196          -777.0                    -777.0   \n",
       "12197          -777.0                    -777.0   \n",
       "12198          -777.0                    -777.0   \n",
       "\n",
       "       barometric_tendency_characteristic_24763 barometric_tendency_24763  \n",
       "12194                                    -777.0                    -777.0  \n",
       "12195                                    -777.0                    -777.0  \n",
       "12196                                    -777.0                    -777.0  \n",
       "12197                                    -777.0                    -777.0  \n",
       "12198                                    -777.0                    -777.0  \n",
       "\n",
       "[5 rows x 358 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " with open(f\"datasetsv2/{st_dict['id']}_test_data.pkl\", 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "vital-enforcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Киренск\n",
      "Витим\n",
      "Пеледуй\n",
      "Крестовский Лесоучасток\n",
      "Ленск\n",
      "Олекминск\n",
      "Покровск\n",
      "Якутск\n",
      "Батамай\n",
      "Сангар\n"
     ]
    }
   ],
   "source": [
    "inference = pd.DataFrame()\n",
    "\n",
    "for st_dict in target_stations:\n",
    "    print(st_dict['name'])\n",
    "    with open(f\"datasetsv2/{st_dict['id']}_test_data.pkl\", 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "    with open(f\"modelsv2/model_{st_dict['id']}.pkl\", 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        \n",
    "    wcode = list(test_data.filter(regex='water_code').columns)\n",
    "    X = test_data.drop(['station_id','date','year','delta_stage_max'] + wcode,axis=1).to_numpy()\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    inference = inference.append(\n",
    "        pd.DataFrame({\n",
    "            'year': test_data.year,\n",
    "            'station_id': test_data.station_id,\n",
    "            'month': test_data.month,\n",
    "            'day': test_data.day,\n",
    "            'date': test_data.date,\n",
    "            'delta_stage_max':  y_pred\n",
    "        }),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "with open('inference.pkl', 'wb') as f:\n",
    "    pickle.dump(inference, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "forbidden-salvation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993.0</td>\n",
       "      <td>3019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993.0</td>\n",
       "      <td>3019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993.0</td>\n",
       "      <td>3019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993.0</td>\n",
       "      <td>3019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993.0</td>\n",
       "      <td>3019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23648</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>2.379107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23649</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>2.379107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23650</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>2.379107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23651</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>2.379107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23652</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>2.379107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23653 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  station_id  month    day       date  delta_stage_max\n",
       "0      1993.0      3019.0    4.0  111.0 1993-04-21         0.520431\n",
       "1      1993.0      3019.0    4.0  112.0 1993-04-22         0.520431\n",
       "2      1993.0      3019.0    4.0  113.0 1993-04-23         0.520431\n",
       "3      1993.0      3019.0    4.0  114.0 1993-04-24         0.520431\n",
       "4      1993.0      3019.0    4.0  115.0 1993-04-25         0.520431\n",
       "...       ...         ...    ...    ...        ...              ...\n",
       "23648  2013.0      3050.0    5.0  137.0 2013-05-17         2.379107\n",
       "23649  2013.0      3050.0    5.0  137.0 2013-05-17         2.379107\n",
       "23650  2013.0      3050.0    5.0  138.0 2013-05-18         2.379107\n",
       "23651  2013.0      3050.0    5.0  138.0 2013-05-18         2.379107\n",
       "23652  2013.0      3050.0    5.0  138.0 2013-05-18         2.379107\n",
       "\n",
       "[23653 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "contained-pulse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>9.270253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  station_id  month  day       date  delta_stage_max\n",
       "0     1993        3019      4  111 1993-04-21         0.520431\n",
       "1     1993        3019      4  112 1993-04-22         0.520431\n",
       "2     1993        3019      4  113 1993-04-23         0.520431\n",
       "3     1993        3019      4  114 1993-04-24         0.520431\n",
       "4     1993        3019      4  115 1993-04-25         0.520431\n",
       "...    ...         ...    ...  ...        ...              ...\n",
       "2480  2013        3230      5  134 2013-05-14         9.270253\n",
       "2481  2013        3230      5  135 2013-05-15         9.262766\n",
       "2482  2013        3230      5  136 2013-05-16         9.262766\n",
       "2483  2013        3230      5  137 2013-05-17         9.262766\n",
       "2484  2013        3230      5  138 2013-05-18         9.325249\n",
       "\n",
       "[2485 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  \n",
    "submit = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "\n",
    "for i in range(len(submit)):\n",
    "    target_date = submit.loc[i, 'date']\n",
    "    target_st = submit.loc[i, 'station_id']\n",
    "    with open(f\"datasetsv2/{target_st}_test_data.pkl\", 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    input_data = data[(data.station_id==target_st)&(data.date==target_date)]\n",
    "    wcode = list(input_data.filter(regex='water_code').columns)\n",
    "    target = list(input_data.filter(regex='delta_stage_max').columns)\n",
    "    X = input_data.drop(['station_id','date','year']+wcode+target,axis=1).to_numpy()\n",
    "    with open(f\"modelsv2/model_{target_st}.pkl\", 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    submit.loc[i, 'delta_stage_max'] = model.predict(X)[0]\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "according-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submition.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "missing-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>9.270253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  station_id  month  day       date  delta_stage_max\n",
       "0     1993        3019      4  111 1993-04-21         0.520431\n",
       "1     1993        3019      4  112 1993-04-22         0.520431\n",
       "2     1993        3019      4  113 1993-04-23         0.520431\n",
       "3     1993        3019      4  114 1993-04-24         0.520431\n",
       "4     1993        3019      4  115 1993-04-25         0.520431\n",
       "...    ...         ...    ...  ...        ...              ...\n",
       "2480  2013        3230      5  134 2013-05-14         9.270253\n",
       "2481  2013        3230      5  135 2013-05-15         9.262766\n",
       "2482  2013        3230      5  136 2013-05-16         9.262766\n",
       "2483  2013        3230      5  137 2013-05-17         9.262766\n",
       "2484  2013        3230      5  138 2013-05-18         9.325249\n",
       "\n",
       "[2485 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "\n",
    "for day in test['date'].unique():\n",
    "    for station in test['station_id'].unique():\n",
    "        test.loc[(test['date']==day) & (test['station_id']==station), 'delta_stage_max'] = \\\n",
    "        submit.loc[(submit['date']==day) & (submit['station_id']==station)]['delta_stage_max']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "featured-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values(by=['date', 'station_id'], inplace=True)\n",
    "test.to_csv('submition.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "angry-bible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year               0\n",
       "station_id         0\n",
       "month              0\n",
       "day                0\n",
       "date               0\n",
       "delta_stage_max    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_submit.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "trained-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "_submit.to_csv('submition.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-williams",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-october",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-eugene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-invite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "committed-explanation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>9.270253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>9.262766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  station_id  month  day       date  delta_stage_max\n",
       "0     1993        3019      4  111 1993-04-21         0.520431\n",
       "1     1993        3019      4  112 1993-04-22         0.520431\n",
       "2     1993        3019      4  113 1993-04-23         0.520431\n",
       "3     1993        3019      4  114 1993-04-24         0.520431\n",
       "4     1993        3019      4  115 1993-04-25         0.520431\n",
       "...    ...         ...    ...  ...        ...              ...\n",
       "2480  2013        3230      5  134 2013-05-14         9.270253\n",
       "2481  2013        3230      5  135 2013-05-15         9.262766\n",
       "2482  2013        3230      5  136 2013-05-16         9.262766\n",
       "2483  2013        3230      5  137 2013-05-17         9.262766\n",
       "2484  2013        3230      5  138 2013-05-18         9.325249\n",
       "\n",
       "[2485 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "strong-windows",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_x</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month_x</th>\n",
       "      <th>day_x</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max_x</th>\n",
       "      <th>year_y</th>\n",
       "      <th>month_y</th>\n",
       "      <th>day_y</th>\n",
       "      <th>delta_stage_max_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>9.325249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6223 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year_x  station_id  month_x  day_x       date  delta_stage_max_x  \\\n",
       "0       1993        3019        4    111 1993-04-21                NaN   \n",
       "1       1993        3019        4    112 1993-04-22                NaN   \n",
       "2       1993        3019        4    113 1993-04-23                NaN   \n",
       "3       1993        3019        4    114 1993-04-24                NaN   \n",
       "4       1993        3019        4    115 1993-04-25                NaN   \n",
       "...      ...         ...      ...    ...        ...                ...   \n",
       "6218    2013        3230        5    138 2013-05-18                NaN   \n",
       "6219    2013        3230        5    138 2013-05-18                NaN   \n",
       "6220    2013        3230        5    138 2013-05-18                NaN   \n",
       "6221    2013        3230        5    138 2013-05-18                NaN   \n",
       "6222    2013        3230        5    138 2013-05-18                NaN   \n",
       "\n",
       "      year_y  month_y  day_y  delta_stage_max_y  \n",
       "0       1993        4    111           0.520431  \n",
       "1       1993        4    112           0.520431  \n",
       "2       1993        4    113           0.520431  \n",
       "3       1993        4    114           0.520431  \n",
       "4       1993        4    115           0.520431  \n",
       "...      ...      ...    ...                ...  \n",
       "6218    2013        5    138           9.325249  \n",
       "6219    2013        5    138           9.325249  \n",
       "6220    2013        5    138           9.325249  \n",
       "6221    2013        5    138           9.325249  \n",
       "6222    2013        5    138           9.325249  \n",
       "\n",
       "[6223 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "_submit = pd.merge(test, submit, on=['station_id','date'])\n",
    "_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-disease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-stuart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-conservative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-pearl",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "constant-lyric",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set using a multi-index selection indexer with a different length than the value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5e4330f97733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'delta_stage_max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delta_stage_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1665\u001b[0m                     \u001b[0;31m# Exclude zero-len for e.g. boolean masking that is all-false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m                     raise ValueError(\n\u001b[0;32m-> 1667\u001b[0;31m                         \u001b[0;34m\"cannot set using a multi-index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m                         \u001b[0;34m\"selection indexer with a different \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                         \u001b[0;34m\"length than the value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set using a multi-index selection indexer with a different length than the value"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "\n",
    "for day in submit['date'].unique():\n",
    "    for station in submit['station_id'].unique():\n",
    "        submit.loc[(submit['date']==day) & (submit['station_id']==station), 'delta_stage_max'] = \\\n",
    "        inference.loc[(inference['date']==day) & (inference['station_id']==station)]['delta_stage_max'].values\n",
    "        \n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-music",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "recovered-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                  0\n",
       "station_id            0\n",
       "month                 0\n",
       "day                   0\n",
       "date                  0\n",
       "delta_stage_max    2485\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "submit.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "sapphire-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                     0\n",
       "station_id               0\n",
       "month                    0\n",
       "day                      0\n",
       "date                     0\n",
       "delta_stage_max_x    69727\n",
       "delta_stage_max_y        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.merge(submit, inference[['station_id','date','delta_stage_max']], how='left', on=['station_id','date'])\n",
    "s.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "gentle-lesson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69727 entries, 0 to 69726\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   year               69727 non-null  int64         \n",
      " 1   station_id         69727 non-null  int64         \n",
      " 2   month              69727 non-null  int64         \n",
      " 3   day                69727 non-null  int64         \n",
      " 4   date               69727 non-null  datetime64[ns]\n",
      " 5   delta_stage_max_y  69727 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(4)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "s.drop('delta_stage_max_x',axis=1,inplace=True)\n",
    "s.rename({'delta_stage_max_y':'delta_stage_max'})\n",
    "s.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "diagnostic-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-racing",
   "metadata": {},
   "source": [
    "### Train v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "accompanied-metro",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Киренск\n",
      "model_3019_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 9.39ms\tremaining: 9.38s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 6.04s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3019_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 6.46ms\tremaining: 6.45s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.95s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3019_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 6.34ms\tremaining: 6.34s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 6.04s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3019_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 7.25ms\tremaining: 7.24s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.97s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3019_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 6.73ms\tremaining: 6.72s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.93s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3019_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 9.2ms\tremaining: 9.19s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 6.05s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3019_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 6.93ms\tremaining: 6.92s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 6s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Витим\n",
      "model_3027_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 6.77ms\tremaining: 6.76s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3027_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 6.96ms\tremaining: 6.96s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.85s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3027_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 6.05ms\tremaining: 6.04s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.85s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3027_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 8.2ms\tremaining: 8.2s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.97s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3027_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 5.84ms\tremaining: 5.83s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.98s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3027_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 8.53ms\tremaining: 8.52s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.96s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3027_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 6.16ms\tremaining: 6.15s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.97s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Пеледуй\n",
      "model_3028_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 8.38ms\tremaining: 8.37s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.96s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3028_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 6.67ms\tremaining: 6.66s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 6.01s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3028_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 6.64ms\tremaining: 6.64s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 6.06s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3028_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 10ms\tremaining: 10s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.84s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3028_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 6.52ms\tremaining: 6.51s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.99s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3028_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 7.84ms\tremaining: 7.84s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.79s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3028_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 7.32ms\tremaining: 7.31s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Крестовский Лесоучасток\n",
      "model_3029_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 6.43ms\tremaining: 6.42s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 6.02s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3029_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 6.98ms\tremaining: 6.98s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.98s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3029_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 6.63ms\tremaining: 6.62s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.87s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3029_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 5.97ms\tremaining: 5.96s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.85s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3029_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 6.54ms\tremaining: 6.54s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.79s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3029_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 6.33ms\tremaining: 6.32s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.92s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3029_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 6.87ms\tremaining: 6.86s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Ленск\n",
      "model_3030_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 5.93ms\tremaining: 5.92s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.77s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3030_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 6.11ms\tremaining: 6.1s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.83s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3030_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 11ms\tremaining: 11s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.81s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3030_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 7.43ms\tremaining: 7.43s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.81s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3030_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 7.08ms\tremaining: 7.08s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.84s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3030_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 5.93ms\tremaining: 5.93s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.89s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3030_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 6.33ms\tremaining: 6.32s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.74s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Олекминск\n",
      "model_3035_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 5.94ms\tremaining: 5.93s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3035_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 7.54ms\tremaining: 7.53s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.78s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3035_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 5.99ms\tremaining: 5.98s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.73s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3035_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 5.97ms\tremaining: 5.96s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.75s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3035_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 6.36ms\tremaining: 6.35s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.78s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3035_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 5.92ms\tremaining: 5.91s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.91s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3035_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 8.9ms\tremaining: 8.89s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Покровск\n",
      "model_3041_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 7.42ms\tremaining: 7.42s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.75s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3041_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 6.2ms\tremaining: 6.2s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.87s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3041_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 7.42ms\tremaining: 7.42s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.84s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3041_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 6.12ms\tremaining: 6.11s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3041_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 6.25ms\tremaining: 6.24s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3041_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 5.92ms\tremaining: 5.92s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.75s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3041_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 6ms\tremaining: 6s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.74s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Якутск\n",
      "model_3045_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 6.18ms\tremaining: 6.17s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.72s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3045_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 6.21ms\tremaining: 6.21s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.74s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3045_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 6.09ms\tremaining: 6.08s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.81s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3045_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 5.97ms\tremaining: 5.96s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.78s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3045_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 6.46ms\tremaining: 6.45s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.76s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3045_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 6.45ms\tremaining: 6.45s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.87s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3045_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 7.47ms\tremaining: 7.46s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.88s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Батамай\n",
      "model_3230_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 6.07ms\tremaining: 6.07s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.74s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3230_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 5.99ms\tremaining: 5.99s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.76s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3230_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 6.1ms\tremaining: 6.09s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.93s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3230_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 6.02ms\tremaining: 6.02s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.76s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3230_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 6.6ms\tremaining: 6.59s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.77s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3230_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 5.9ms\tremaining: 5.9s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.76s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3230_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 6.45ms\tremaining: 6.45s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 6.06s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n",
      "Сангар\n",
      "model_3050_1\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1187320\ttest: 12.3748132\tbest: 12.3748132 (0)\ttotal: 6.35ms\tremaining: 6.35s\n",
      "999:\tlearn: 1.9240161\ttest: 12.1417735\tbest: 11.7615089 (55)\ttotal: 5.76s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.76150888\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "model_3050_2\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1271001\ttest: 12.3816905\tbest: 12.3816905 (0)\ttotal: 5.96ms\tremaining: 5.95s\n",
      "999:\tlearn: 1.8610692\ttest: 11.9037568\tbest: 11.6233772 (90)\ttotal: 5.75s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.62337725\n",
      "bestIteration = 90\n",
      "\n",
      "Shrink model to first 91 iterations.\n",
      "model_3050_3\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0720217\ttest: 12.3602155\tbest: 12.3602155 (0)\ttotal: 8.9ms\tremaining: 8.89s\n",
      "999:\tlearn: 1.9721651\ttest: 11.8154599\tbest: 11.5849534 (133)\ttotal: 5.77s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.58495343\n",
      "bestIteration = 133\n",
      "\n",
      "Shrink model to first 134 iterations.\n",
      "model_3050_4\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1052716\ttest: 12.3799742\tbest: 12.3799742 (0)\ttotal: 6.77ms\tremaining: 6.76s\n",
      "999:\tlearn: 1.9573930\ttest: 11.7994902\tbest: 11.5434453 (102)\ttotal: 5.73s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.54344535\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "model_3050_5\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0804082\ttest: 12.3701545\tbest: 12.3701545 (0)\ttotal: 5.9ms\tremaining: 5.9s\n",
      "999:\tlearn: 2.0304061\ttest: 12.0550898\tbest: 11.7335757 (84)\ttotal: 5.76s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.73357566\n",
      "bestIteration = 84\n",
      "\n",
      "Shrink model to first 85 iterations.\n",
      "model_3050_6\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.0818374\ttest: 12.3916648\tbest: 12.3916648 (0)\ttotal: 6.86ms\tremaining: 6.85s\n",
      "999:\tlearn: 2.0713445\ttest: 12.1786014\tbest: 11.9547681 (89)\ttotal: 5.87s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.95476812\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "model_3050_7\n",
      "Learning rate set to 0.054017\n",
      "0:\tlearn: 12.1078054\ttest: 12.4033446\tbest: 12.4033446 (0)\ttotal: 9.94ms\tremaining: 9.93s\n",
      "999:\tlearn: 2.0028004\ttest: 12.4134699\tbest: 12.0710864 (70)\ttotal: 5.94s\tremaining: 0us\n",
      "\n",
      "bestTest = 12.07108645\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n"
     ]
    }
   ],
   "source": [
    "for st_dict in target_stations:\n",
    "    print(st_dict['name'])\n",
    "    with open(f\"datasets/{st_dict['name']}_train_data.pkl\", 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "        \n",
    "    train_data['delta_stage_max_1'] = train_data.delta_stage_max.shift(1)\n",
    "    train_data['delta_stage_max_2'] = train_data.delta_stage_max.shift(2)\n",
    "    train_data['delta_stage_max_3'] = train_data.delta_stage_max.shift(3)\n",
    "    train_data['delta_stage_max_4'] = train_data.delta_stage_max.shift(4)\n",
    "    train_data['delta_stage_max_5'] = train_data.delta_stage_max.shift(5)\n",
    "    train_data['delta_stage_max_6'] = train_data.delta_stage_max.shift(6)\n",
    "    train_data['delta_stage_max_7'] = train_data.delta_stage_max.shift(7)\n",
    "    train_data.dropna(inplace=True)\n",
    "\n",
    "    wcode = list(data.filter(regex='water_code').columns)\n",
    "    target = list(data.filter(regex='delta_stage_max').columns)\n",
    "    X = data.drop(['station_id','date','year']+wcode+target,axis=1).to_numpy()\n",
    "    y1 = data.delta_stage_max_1.to_numpy()\n",
    "    y2 = data.delta_stage_max_2.to_numpy()\n",
    "    y3 = data.delta_stage_max_3.to_numpy()\n",
    "    y4 = data.delta_stage_max_4.to_numpy()\n",
    "    y5 = data.delta_stage_max_5.to_numpy()\n",
    "    y6 = data.delta_stage_max_6.to_numpy()\n",
    "    y7 = data.delta_stage_max_7.to_numpy()\n",
    "\n",
    "    X_train, X_test, y1_train, y1_test = train_test_split(X, y1, shuffle=False, train_size=0.2, random_state=13)\n",
    "    _, _, y2_train, y2_test = train_test_split(X, y2, shuffle=False, train_size=0.2, random_state=13)\n",
    "    _, _, y3_train, y3_test = train_test_split(X, y3, shuffle=False, train_size=0.2, random_state=13)\n",
    "    _, _, y4_train, y4_test = train_test_split(X, y4, shuffle=False, train_size=0.2, random_state=13)\n",
    "    _, _, y5_train, y5_test = train_test_split(X, y5, shuffle=False, train_size=0.2, random_state=13)\n",
    "    _, _, y6_train, y6_test = train_test_split(X, y6, shuffle=False, train_size=0.2, random_state=13)\n",
    "    _, _, y7_train, y7_test = train_test_split(X, y7, shuffle=False, train_size=0.2, random_state=13)\n",
    "    \n",
    "    # тренировка модели\n",
    "    params = {\n",
    "        'iterations': 1000,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': 13,\n",
    "        'use_best_model': True\n",
    "    }\n",
    "    \n",
    "    y_train = [y1_train,y2_train,y3_train,y4_train,y5_train,y6_train,y7_train]\n",
    "    y_test = [y1_test,y2_test,y3_test,y4_test,y5_test,y6_test,y7_test]\n",
    "\n",
    "    for i in range(1,8):\n",
    "        model_name = f\"model_{st_dict['id']}_{i}\"\n",
    "        print(model_name)\n",
    "        model = catboost.CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train[i-1],\n",
    "            eval_set=(X_test, y_test[i-1]),\n",
    "            verbose=1000\n",
    "        )\n",
    "#         print(f'сохранение модели {model_name}')\n",
    "        with open(f'models/{model_name}.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-happiness",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blessed-cursor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3019: 'Киренск',\n",
       " 3027: 'Витим',\n",
       " 3028: 'Пеледуй',\n",
       " 3029: 'Крестовский Лесоучасток',\n",
       " 3030: 'Ленск',\n",
       " 3035: 'Олекминск',\n",
       " 3041: 'Покровск',\n",
       " 3045: 'Якутск',\n",
       " 3230: 'Батамай',\n",
       " 3050: 'Сангар'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = dict()\n",
    "\n",
    "for st in target_stations:\n",
    "    mapper[st['id']] = st['name']\n",
    "    \n",
    "mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-brave",
   "metadata": {},
   "source": [
    "submit = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "\n",
    "for i in range(0, len(submit), 7):\n",
    "    target_date = submit.loc[i, 'date']\n",
    "    target_st = submit.loc[i, 'station_id']\n",
    "    data_date = target_date - pd.Timedelta(days=1)\n",
    "    with open(f\"datasets/{mapper[target_st]}_train_data.pkl\", 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    input_data = data[(data.station_id==target_st)&(data.date==data_date)]\n",
    "    wcode = list(input_data.filter(regex='water_code').columns)\n",
    "    target = list(input_data.filter(regex='delta_stage_max').columns)\n",
    "    X = input_data.drop(['station_id','date','year']+wcode+target,axis=1).to_numpy()\n",
    "    for j in range(1,8):\n",
    "        with open(f\"models/model_{target_st}_{j}.pkl\", 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        submit.loc[i, 'delta_stage_max'] = model.predict(X)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-bhutan",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "broken-jones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Киренск\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3019\n",
      "Learning rate set to 0.054021\n",
      "0:\tlearn: 12.1163635\ttest: 12.4009006\tbest: 12.4009006 (0)\ttotal: 7.25ms\tremaining: 7.24s\n",
      "999:\tlearn: 2.0550281\ttest: 12.1034395\tbest: 11.8747255 (179)\ttotal: 6.17s\tremaining: 0us\n",
      "\n",
      "bestTest = 11.87472545\n",
      "bestIteration = 179\n",
      "\n",
      "Shrink model to first 180 iterations.\n",
      "Витим\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3027\n",
      "Learning rate set to 0.054475\n",
      "0:\tlearn: 30.4538145\ttest: 32.6849750\tbest: 32.6849750 (0)\ttotal: 15ms\tremaining: 15s\n",
      "999:\tlearn: 2.4596669\ttest: 26.9910279\tbest: 26.9910279 (999)\ttotal: 10.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 26.9910279\n",
      "bestIteration = 999\n",
      "\n",
      "Пеледуй\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3028\n",
      "Learning rate set to 0.05456\n",
      "0:\tlearn: 30.3336401\ttest: 35.1099534\tbest: 35.1099534 (0)\ttotal: 12.8ms\tremaining: 12.8s\n",
      "999:\tlearn: 2.3461319\ttest: 29.4841398\tbest: 29.4841398 (999)\ttotal: 10.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 29.4841398\n",
      "bestIteration = 999\n",
      "\n",
      "Крестовский Лесоучасток\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3029\n",
      "Learning rate set to 0.054602\n",
      "0:\tlearn: 34.3200689\ttest: 34.8885610\tbest: 34.8885610 (0)\ttotal: 14.3ms\tremaining: 14.3s\n",
      "999:\tlearn: 2.7309009\ttest: 25.6887987\tbest: 25.6760005 (909)\ttotal: 10.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 25.67600055\n",
      "bestIteration = 909\n",
      "\n",
      "Shrink model to first 910 iterations.\n",
      "Ленск\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3030\n",
      "Learning rate set to 0.054602\n",
      "0:\tlearn: 32.6373434\ttest: 38.1323162\tbest: 38.1323162 (0)\ttotal: 11.7ms\tremaining: 11.7s\n",
      "999:\tlearn: 2.0589977\ttest: 29.0887792\tbest: 29.0851676 (833)\ttotal: 10.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 29.08516764\n",
      "bestIteration = 833\n",
      "\n",
      "Shrink model to first 834 iterations.\n",
      "Олекминск\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3035\n",
      "Learning rate set to 0.054602\n",
      "0:\tlearn: 21.2210657\ttest: 25.2937222\tbest: 25.2937222 (0)\ttotal: 20.3ms\tremaining: 20.3s\n",
      "999:\tlearn: 1.9495640\ttest: 22.8331312\tbest: 22.6767644 (270)\ttotal: 11.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 22.67676443\n",
      "bestIteration = 270\n",
      "\n",
      "Shrink model to first 271 iterations.\n",
      "Покровск\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3041\n",
      "Learning rate set to 0.054602\n",
      "0:\tlearn: 18.1440487\ttest: 19.9895993\tbest: 19.9895993 (0)\ttotal: 9.8ms\tremaining: 9.79s\n",
      "999:\tlearn: 2.1647065\ttest: 17.4973449\tbest: 17.4779819 (540)\ttotal: 8.51s\tremaining: 0us\n",
      "\n",
      "bestTest = 17.4779819\n",
      "bestIteration = 540\n",
      "\n",
      "Shrink model to first 541 iterations.\n",
      "Якутск\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3045\n",
      "Learning rate set to 0.054602\n",
      "0:\tlearn: 21.9894157\ttest: 22.5554328\tbest: 22.5554328 (0)\ttotal: 9.05ms\tremaining: 9.05s\n",
      "999:\tlearn: 2.2028877\ttest: 19.5696100\tbest: 19.5240689 (476)\ttotal: 8.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 19.52406886\n",
      "bestIteration = 476\n",
      "\n",
      "Shrink model to first 477 iterations.\n",
      "Батамай\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3230\n",
      "Learning rate set to 0.054291\n",
      "0:\tlearn: 20.9081769\ttest: 21.0734550\tbest: 21.0734550 (0)\ttotal: 9.04ms\tremaining: 9.03s\n",
      "999:\tlearn: 2.0424637\ttest: 17.5844550\tbest: 17.0946529 (168)\ttotal: 8.39s\tremaining: 0us\n",
      "\n",
      "bestTest = 17.09465293\n",
      "bestIteration = 168\n",
      "\n",
      "Shrink model to first 169 iterations.\n",
      "Сангар\n",
      "формируем тренировочный датасет\n",
      "тренировка модели\n",
      "model_3050\n",
      "Learning rate set to 0.054526\n",
      "0:\tlearn: 23.7213552\ttest: 22.1052625\tbest: 22.1052625 (0)\ttotal: 8.94ms\tremaining: 8.94s\n",
      "999:\tlearn: 2.4737229\ttest: 19.4422166\tbest: 19.2954572 (204)\ttotal: 8.54s\tremaining: 0us\n",
      "\n",
      "bestTest = 19.29545717\n",
      "bestIteration = 204\n",
      "\n",
      "Shrink model to first 205 iterations.\n"
     ]
    }
   ],
   "source": [
    "# по каждому целевому посту тренируем модель\n",
    "verbose = False\n",
    "for st_dict in target_stations:\n",
    "    print(st_dict['name'])\n",
    "    # формируем тренировочный датасет\n",
    "    print('формируем тренировочный датасет')\n",
    "    gydro_df = make_gydro_df(\n",
    "        pd.read_csv(f'{RAWDATADIR}/track_2_package/train.csv', parse_dates=['date']),\n",
    "        st_dict\n",
    "    )\n",
    "    if verbose: print('gydro_df', gydro_df.shape)\n",
    "\n",
    "    meteo_df = make_meteo_df(\n",
    "        pd.read_csv(f'{RAWDATADIR}/track_2_package/meteo_3hours.csv', parse_dates=['date_local']),\n",
    "        st_dict['meteo_st']\n",
    "    )\n",
    "    if verbose: print('meteo_df', meteo_df.shape)\n",
    "\n",
    "    train_data = pd.merge(gydro_df, meteo_df.rename(columns={'date_local': 'date'}), how='left', on='date')\n",
    "    if verbose: print('train_data',train_data.shape)\n",
    "\n",
    "    train_data.fillna(-777, inplace=True)\n",
    "    if verbose: print('NaNs', sum(train_data.isna().sum()))\n",
    "    if verbose: print('train_data', train_data.shape)\n",
    "\n",
    "    with open(f\"{st_dict['name']}_train_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(train_data, f)\n",
    "    \n",
    "    wcode = list(train_data.filter(regex='water_code').columns)\n",
    "    X = train_data.drop(['station_id','date','year','delta_stage_max'] + wcode,axis=1).to_numpy()\n",
    "    y = train_data.delta_stage_max.to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, train_size=0.2, random_state=13)\n",
    "    \n",
    "    # тренировка модели\n",
    "    print('тренировка модели')\n",
    "    params = {\n",
    "        'iterations': 1000,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': 13,\n",
    "        'use_best_model': True\n",
    "    }\n",
    "    model_name = f\"model_{st_dict['id']}\"\n",
    "    print(model_name)\n",
    "    model = catboost.CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_test, y_test),\n",
    "        verbose=1000\n",
    "    )\n",
    "    with open(f'models/{model_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-sally",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "herbal-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gydro_raw (4071, 15)\n",
      "meteo_raw (60880, 94)\n"
     ]
    }
   ],
   "source": [
    "dirs = os.listdir('../data/raw/test_data')\n",
    "files = os.listdir('../data/raw/test_data/2_track_cp4')\n",
    "names = ['extra_train.csv','extra_meteo_3hours.csv']\n",
    "\n",
    "gydro_raw = pd.DataFrame()\n",
    "meteo_raw = pd.DataFrame()\n",
    "\n",
    "for d in dirs:\n",
    "    for f in files:\n",
    "        if f in names:\n",
    "            if f == 'extra_train.csv':\n",
    "                gydro_raw = pd.concat([\n",
    "                    gydro_raw, \n",
    "                    pd.read_csv(f'../data/raw/test_data/{d}/{f}', parse_dates=['date']),\n",
    "                ])\n",
    "            if f == 'extra_meteo_3hours.csv':\n",
    "                meteo_raw = pd.concat([\n",
    "                    meteo_raw,\n",
    "                    pd.read_csv(f'../data/raw/test_data/{d}/{f}', parse_dates=['date_local']),\n",
    "                ])\n",
    "print('gydro_raw', gydro_raw.shape)\n",
    "print('meteo_raw', meteo_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "downtown-sigma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Киренск\n",
      "формируем тестовый датасет\n",
      "metric = 5.616622282005717\n",
      "Витим\n",
      "формируем тестовый датасет\n",
      "metric = 4.535487106835195\n",
      "Пеледуй\n",
      "формируем тестовый датасет\n",
      "metric = 4.156872227729615\n",
      "Крестовский Лесоучасток\n",
      "формируем тестовый датасет\n",
      "metric = 10.48437542163091\n",
      "Ленск\n",
      "формируем тестовый датасет\n",
      "metric = 7.182839301753967\n",
      "Олекминск\n",
      "формируем тестовый датасет\n",
      "metric = 6.86643454856629\n",
      "Покровск\n",
      "формируем тестовый датасет\n",
      "metric = 3.5351006879683284\n",
      "Якутск\n",
      "формируем тестовый датасет\n",
      "metric = 1.8576006938137881\n",
      "Батамай\n",
      "формируем тестовый датасет\n",
      "metric = 1.2730671725391538\n",
      "Сангар\n",
      "формируем тестовый датасет\n",
      "metric = 3.737945462506952\n"
     ]
    }
   ],
   "source": [
    "# по каждому посту формируем инференс модели\n",
    "verbose = False\n",
    "inference = pd.DataFrame()\n",
    "\n",
    "for st_dict in target_stations:\n",
    "    print(st_dict['name'])\n",
    "    # формируем тренировочный датасет\n",
    "    print('формируем тестовый датасет')\n",
    "    gydro_df = make_gydro_df(gydro_raw, st_dict)\n",
    "    if verbose: print('gydro_df', gydro_df.shape)\n",
    "\n",
    "    meteo_df = make_meteo_df(meteo_raw, st_dict['meteo_st'])\n",
    "    if verbose: print('meteo_df', meteo_df.shape)\n",
    "\n",
    "    test_data = pd.merge(gydro_df, meteo_df.rename(columns={'date_local': 'date'}), how='left', on='date')\n",
    "    if verbose: print('test_data',test_data.shape)\n",
    "\n",
    "    test_data.fillna(-777, inplace=True)\n",
    "    if verbose: print('NaNs', sum(test_data.isna().sum()))\n",
    "    if verbose: print('test_data', test_data.shape)\n",
    "\n",
    "    with open(f\"{st_dict['name']}_test_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(test_data, f)\n",
    "        \n",
    "    wcode = list(test_data.filter(regex='water_code').columns)\n",
    "    X = test_data.drop(['station_id','date','year','delta_stage_max'] + wcode,axis=1).to_numpy()\n",
    "    y = test_data.delta_stage_max.to_numpy()\n",
    "        \n",
    "    # загружаем натреринованную модель\n",
    "    with open(f\"models/model_{st_dict['id']}.pkl\", 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    print('metric =', mean_squared_error(y, y_pred)/st_dict['std_sq'])\n",
    "    \n",
    "    inference = inference.append(\n",
    "        pd.DataFrame({\n",
    "            'year': test_data.year,\n",
    "            'station_id': test_data.station_id,\n",
    "            'month': test_data.month,\n",
    "            'day': test_data.day,\n",
    "            'date': test_data.date,\n",
    "            'delta_stage_max':  y_pred\n",
    "        }),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "with open('inference.pkl', 'wb') as f:\n",
    "    pickle.dump(inference, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "subtle-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>132</td>\n",
       "      <td>1993-05-12</td>\n",
       "      <td>10.123921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>1993-05-13</td>\n",
       "      <td>8.353861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>1993-05-14</td>\n",
       "      <td>11.329020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>1993-05-15</td>\n",
       "      <td>10.172499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>1993-05-16</td>\n",
       "      <td>4.793744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>2013</td>\n",
       "      <td>3050</td>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>3.123412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>2013</td>\n",
       "      <td>3050</td>\n",
       "      <td>6</td>\n",
       "      <td>156</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>2.981406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>2013</td>\n",
       "      <td>3050</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>3.123412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>2013</td>\n",
       "      <td>3050</td>\n",
       "      <td>6</td>\n",
       "      <td>158</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>5.743994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2013</td>\n",
       "      <td>3050</td>\n",
       "      <td>6</td>\n",
       "      <td>159</td>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>5.825912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2146 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  station_id  month  day       date  delta_stage_max\n",
       "0     1993        3019      5  132 1993-05-12        10.123921\n",
       "1     1993        3019      5  133 1993-05-13         8.353861\n",
       "2     1993        3019      5  134 1993-05-14        11.329020\n",
       "3     1993        3019      5  135 1993-05-15        10.172499\n",
       "4     1993        3019      5  136 1993-05-16         4.793744\n",
       "...    ...         ...    ...  ...        ...              ...\n",
       "2141  2013        3050      6  155 2013-06-04         3.123412\n",
       "2142  2013        3050      6  156 2013-06-05         2.981406\n",
       "2143  2013        3050      6  157 2013-06-06         3.123412\n",
       "2144  2013        3050      6  158 2013-06-07         5.743994\n",
       "2145  2013        3050      6  159 2013-06-08         5.825912\n",
       "\n",
       "[2146 rows x 6 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "virtual-procedure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  station_id  month  day       date  delta_stage_max\n",
       "0     1993        3019      4  111 1993-04-21              NaN\n",
       "1     1993        3019      4  112 1993-04-22              NaN\n",
       "2     1993        3019      4  113 1993-04-23              NaN\n",
       "3     1993        3019      4  114 1993-04-24              NaN\n",
       "4     1993        3019      4  115 1993-04-25              NaN\n",
       "...    ...         ...    ...  ...        ...              ...\n",
       "2480  2013        3230      5  134 2013-05-14              NaN\n",
       "2481  2013        3230      5  135 2013-05-15              NaN\n",
       "2482  2013        3230      5  136 2013-05-16              NaN\n",
       "2483  2013        3230      5  137 2013-05-17              NaN\n",
       "2484  2013        3230      5  138 2013-05-18              NaN\n",
       "\n",
       "[2485 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# формируем сабмит\n",
    "submit = pd.read_csv('../data/raw/test_data/2_track_cp4/test.csv', parse_dates=['date'])\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "acquired-relevance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>1993-04-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1993-04-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1997-04-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1997</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1997-04-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1997</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1997-04-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1997</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1997-04-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1997</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1997-04-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1997</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>1997-04-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1997</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1997-04-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2001</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>2001-04-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2001</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2001-04-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2001</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>2001-04-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2001</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>2001-04-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2001</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>2001-04-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2001</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>2001-04-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  station_id  month  day       date  delta_stage_max\n",
       "0   1993        3019      4  111 1993-04-21              NaN\n",
       "1   1993        3019      4  112 1993-04-22              NaN\n",
       "2   1993        3019      4  113 1993-04-23              NaN\n",
       "3   1993        3019      4  114 1993-04-24              NaN\n",
       "4   1993        3019      4  115 1993-04-25              NaN\n",
       "5   1993        3019      4  116 1993-04-26              NaN\n",
       "6   1993        3019      4  117 1993-04-27              NaN\n",
       "7   1997        3019      4  111 1997-04-21              NaN\n",
       "8   1997        3019      4  112 1997-04-22              NaN\n",
       "9   1997        3019      4  113 1997-04-23              NaN\n",
       "10  1997        3019      4  114 1997-04-24              NaN\n",
       "11  1997        3019      4  115 1997-04-25              NaN\n",
       "12  1997        3019      4  116 1997-04-26              NaN\n",
       "13  1997        3019      4  117 1997-04-27              NaN\n",
       "14  2001        3019      4  111 2001-04-21              NaN\n",
       "15  2001        3019      4  112 2001-04-22              NaN\n",
       "16  2001        3019      4  113 2001-04-23              NaN\n",
       "17  2001        3019      4  114 2001-04-24              NaN\n",
       "18  2001        3019      4  115 2001-04-25              NaN\n",
       "19  2001        3019      4  116 2001-04-26              NaN"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "manual-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Киренск_train_data.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "previous-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stage_avg</th>\n",
       "      <th>stage_min</th>\n",
       "      <th>stage_max</th>\n",
       "      <th>temp</th>\n",
       "      <th>water_code</th>\n",
       "      <th>ice_thickness</th>\n",
       "      <th>snow_height</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>air_temperature_max_before_30230</th>\n",
       "      <th>air_max_temperature_30230</th>\n",
       "      <th>water_vapour_partial_pressure_30230</th>\n",
       "      <th>relative_humidity_30230</th>\n",
       "      <th>vapour_pressure_deficit_30230</th>\n",
       "      <th>dew_point_temperature_30230</th>\n",
       "      <th>pressure_30230</th>\n",
       "      <th>pressure_sea_level_30230</th>\n",
       "      <th>barometric_tendency_characteristic_30230</th>\n",
       "      <th>barometric_tendency_30230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>3019</td>\n",
       "      <td>1993-04-20</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>53.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.52</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>989.9</td>\n",
       "      <td>1022.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id       date  stage_avg  stage_min  stage_max  temp water_code  \\\n",
       "2975        3019 1993-04-20       35.0       31.0       38.0   0.0         15   \n",
       "\n",
       "      ice_thickness  snow_height  place  ...  \\\n",
       "2975           53.0         10.0      1  ...   \n",
       "\n",
       "      air_temperature_max_before_30230  air_max_temperature_30230  \\\n",
       "2975                              2.35                       0.95   \n",
       "\n",
       "      water_vapour_partial_pressure_30230  relative_humidity_30230  \\\n",
       "2975                                 2.52                     40.0   \n",
       "\n",
       "      vapour_pressure_deficit_30230  dew_point_temperature_30230  \\\n",
       "2975                           3.86                        -11.6   \n",
       "\n",
       "      pressure_30230  pressure_sea_level_30230  \\\n",
       "2975           989.9                    1022.3   \n",
       "\n",
       "      barometric_tendency_characteristic_30230 barometric_tendency_30230  \n",
       "2975                                       3.0                       0.5  \n",
       "\n",
       "[1 rows x 250 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.date==pd.to_datetime('1993-04-20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "metropolitan-compact",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for row in submit.iterrows():\n",
    "    print(inference[(inference.station_id==row[1]['station_id'])& \\\n",
    "                    (inference.year==row[1]['year'])& \\\n",
    "                    (inference.month==row[1]['month'])& \\\n",
    "                    (inference.day==row[1]['day'])\n",
    "                   ].delta_stage_max.values)\n",
    "#     print(row[1]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "geological-silence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year station_id month  day       date delta_stage_max\n",
       "0     1993       3019     4  111 1993-04-21             NaN\n",
       "1     1993       3019     4  112 1993-04-22             NaN\n",
       "2     1993       3019     4  113 1993-04-23             NaN\n",
       "3     1993       3019     4  114 1993-04-24             NaN\n",
       "4     1993       3019     4  115 1993-04-25             NaN\n",
       "...    ...        ...   ...  ...        ...             ...\n",
       "2480  2013       3230     5  134 2013-05-14             NaN\n",
       "2481  2013       3230     5  135 2013-05-15             NaN\n",
       "2482  2013       3230     5  136 2013-05-16             NaN\n",
       "2483  2013       3230     5  137 2013-05-17             NaN\n",
       "2484  2013       3230     5  138 2013-05-18             NaN\n",
       "\n",
       "[2485 rows x 6 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_subm = pd.DataFrame(columns=list(submit.columns))\n",
    "for row in submit.iterrows():\n",
    "    dsm = inference[(inference.station_id==row[1]['station_id'])&(inference.date==row[1]['date'])].delta_stage_max.values\n",
    "    if len(dsm)>0:\n",
    "        dsm = dsm[0]\n",
    "    else:\n",
    "        dsm = np.nan\n",
    "    _subm = _subm.append({\n",
    "        'year': row[1]['year'],\n",
    "        'station_id': row[1]['station_id'], \n",
    "        'month': row[1]['month'],\n",
    "        'day': row[1]['day'],\n",
    "        'date': row[1]['date'],\n",
    "        'delta_stage_max': dsm\n",
    "    }, ignore_index=True)\n",
    "_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "optional-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                  0\n",
       "station_id            0\n",
       "month                 0\n",
       "day                   0\n",
       "date                  0\n",
       "delta_stage_max    2485\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_subm.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-constant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-header",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-couple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "korean-promise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>1993-04-28</td>\n",
       "      <td>5.669994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>1993-04-29</td>\n",
       "      <td>8.005963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1993-04-30</td>\n",
       "      <td>4.806516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  station_id  month  day       date  delta_stage_max\n",
       "56  1993        3019      4  118 1993-04-28         5.669994\n",
       "57  1993        3019      4  119 1993-04-29         8.005963\n",
       "58  1993        3019      4  120 1993-04-30         4.806516"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference[(inference.station_id==3019)&(inference.month==4)&(inference.year==1993)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "featured-stream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                    0\n",
       "station_id              0\n",
       "month                   0\n",
       "day                     0\n",
       "date                    0\n",
       "delta_stage_max_x    2485\n",
       "delta_stage_max_y    2485\n",
       "dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.merge(submit, inference[['station_id','date','delta_stage_max']], how='left', on=['station_id','date'])\n",
    "s.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "flexible-mother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.delta_stage_max_y.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "built-processing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, station_id, month, day, date, delta_stage_max]\n",
       "Index: []"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference[(inference.date == pd.to_datetime('2013-05-18'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "molecular-transfer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        inference.loc[(inference.station_id == st)&(inference.date == d), 'delta_stage_max'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ambient-auditor",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set using a multi-index selection indexer with a different length than the value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-faadda254090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstation_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstation_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'delta_stage_max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0minference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstation_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_stage_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#             inference[(inference.station_id == st)&(inference.date == d)].delta_stage_max.values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1665\u001b[0m                     \u001b[0;31m# Exclude zero-len for e.g. boolean masking that is all-false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m                     raise ValueError(\n\u001b[0;32m-> 1667\u001b[0;31m                         \u001b[0;34m\"cannot set using a multi-index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m                         \u001b[0;34m\"selection indexer with a different \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                         \u001b[0;34m\"length than the value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set using a multi-index selection indexer with a different length than the value"
     ]
    }
   ],
   "source": [
    "for st in submit.station_id.unique():\n",
    "    print(st)\n",
    "    for d in submit[submit.station_id == st].date.unique():\n",
    "        submit.loc[(submit.station_id == st)&(submit.date == d), 'delta_stage_max'] = \\\n",
    "        inference[(inference.station_id == st)&(inference.date == d)].delta_stage_max.values\n",
    "\n",
    "#             inference[(inference.station_id == st)&(inference.date == d)].delta_stage_max.values\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "seeing-diversity",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-393292fa9bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m inference.loc[\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstation_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ]\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only compare identically-labeled Series objects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "inference.loc[\n",
    "    (inference.year == submit.year)& \\\n",
    "    (inference.station_id == submit.station_id),\n",
    "    :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "growing-trunk",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set using a multi-index selection indexer with a different length than the value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-3db8843a635a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'delta_stage_max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delta_stage_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1665\u001b[0m                     \u001b[0;31m# Exclude zero-len for e.g. boolean masking that is all-false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m                     raise ValueError(\n\u001b[0;32m-> 1667\u001b[0;31m                         \u001b[0;34m\"cannot set using a multi-index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m                         \u001b[0;34m\"selection indexer with a different \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                         \u001b[0;34m\"length than the value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set using a multi-index selection indexer with a different length than the value"
     ]
    }
   ],
   "source": [
    "for day in submit['date'].unique():\n",
    "    for station in submit['station_id'].unique():\n",
    "        submit.loc[(submit['date']==day) & (submit['station_id']==station), 'delta_stage_max'] = \\\n",
    "        inference.loc[(inference['date']==day) & (inference['station_id']==station)]['delta_stage_max'].values\n",
    "        \n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-multimedia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-hayes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-roulette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-breeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-farmer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "according-honolulu",
   "metadata": {},
   "source": [
    "# Отработка методов и подходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "alpha-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{RAWDATADIR}/track_2_package/train.csv', parse_dates=['date'])\n",
    "\n",
    "# удаляем наблюдения за 1985-01-01, т.к. изменение уровня воды NaN из-за отсуютсвтия более ранних исторических данных\n",
    "train_df.drop(train_df[train_df.date == pd.to_datetime('1985-01-01', format='%Y-%m-%d')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-electronics",
   "metadata": {},
   "source": [
    "### Киренск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "german-horror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stage_avg</th>\n",
       "      <th>stage_min</th>\n",
       "      <th>stage_max</th>\n",
       "      <th>temp</th>\n",
       "      <th>water_code</th>\n",
       "      <th>ice_thickness</th>\n",
       "      <th>snow_height</th>\n",
       "      <th>place</th>\n",
       "      <th>discharge</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-01</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-03</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-04</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-05</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>53.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id       date  stage_avg  stage_min  stage_max  temp water_code  \\\n",
       "0        3019 1985-01-01      -23.0      -23.0      -23.0   NaN         16   \n",
       "1        3019 1985-01-02      -23.0      -23.0      -23.0   NaN         16   \n",
       "2        3019 1985-01-03      -23.0      -23.0      -23.0   NaN         16   \n",
       "3        3019 1985-01-04      -24.0      -24.0      -24.0   NaN         16   \n",
       "4        3019 1985-01-05      -24.0      -24.0      -24.0   NaN         16   \n",
       "\n",
       "   ice_thickness  snow_height  place  discharge  year  month  day  \\\n",
       "0            NaN          NaN      0        NaN  1985      1    1   \n",
       "1            NaN          NaN      0        NaN  1985      1    2   \n",
       "2            NaN          NaN      0        NaN  1985      1    3   \n",
       "3            NaN          NaN      0        NaN  1985      1    4   \n",
       "4           53.0         29.0      1        NaN  1985      1    5   \n",
       "\n",
       "   delta_stage_max  \n",
       "0              NaN  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3             -1.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data = train_df[(train_df.station_id == kirensk_dict['id'])].copy()\n",
    "\n",
    "# если замер льда не делали, то пусть 0 будет такой категорией\n",
    "tr_data['place'].fillna(0, inplace=True)\n",
    "# water_code и place должны быть категориальными\n",
    "tr_data['water_code'] = tr_data['water_code'].astype('str')\n",
    "tr_data['place'] = tr_data['place'].astype('int8')\n",
    "\n",
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "changing-motel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp 5372\n",
      "ice_thickness 10945\n",
      "snow_height 10968\n",
      "discharge 11603\n"
     ]
    }
   ],
   "source": [
    "# проверка признаков на наличие пропусков\n",
    "na_features = []\n",
    "for col in tr_data.columns:\n",
    "    cnt = tr_data[col].isna().sum()\n",
    "    if cnt > 0:\n",
    "        print(col, cnt)\n",
    "        na_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "unable-registration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp', 'ice_thickness', 'snow_height', 'discharge']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "unique-olive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temp': {1: 0.0,\n",
       "  2: 0.0,\n",
       "  3: 0.0,\n",
       "  4: 0.09090909090909091,\n",
       "  5: 4.593290322580645,\n",
       "  6: 16.093793103448277,\n",
       "  7: 20.633577712609974,\n",
       "  8: 18.358797653958945,\n",
       "  9: 10.244141414141415,\n",
       "  10: 2.1803519061583576,\n",
       "  11: 0.025,\n",
       "  12: 0.0},\n",
       " 'ice_thickness': {1: 53.78861788617886,\n",
       "  2: 62.458333333333336,\n",
       "  3: 65.61538461538461,\n",
       "  4: 59.13414634146341,\n",
       "  5: 41.0,\n",
       "  6: 0.0,\n",
       "  7: 0.0,\n",
       "  8: 0.0,\n",
       "  9: 0.0,\n",
       "  10: 10.0,\n",
       "  11: 21.8125,\n",
       "  12: 39.77777777777778},\n",
       " 'snow_height': {1: 31.6260162601626,\n",
       "  2: 36.94117647058823,\n",
       "  3: 33.034188034188034,\n",
       "  4: 14.603174603174603,\n",
       "  5: 0.0,\n",
       "  6: 0.0,\n",
       "  7: 0.0,\n",
       "  8: 0.0,\n",
       "  9: 0.0,\n",
       "  10: 5.5,\n",
       "  11: 10.648936170212766,\n",
       "  12: 24.384615384615383},\n",
       " 'discharge': {1: -1,\n",
       "  2: -1,\n",
       "  3: -1,\n",
       "  4: -1,\n",
       "  5: -1,\n",
       "  6: -1,\n",
       "  7: -1,\n",
       "  8: -1,\n",
       "  9: -1,\n",
       "  10: -1,\n",
       "  11: -1,\n",
       "  12: -1}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# находим значения для заполнения праметров с пропусками, учитывая специфику каждого месяца\n",
    "\n",
    "na_features_dict = dict()\n",
    "for f in na_features:\n",
    "    na_features_dict[f] = dict()\n",
    "\n",
    "for feature in na_features:\n",
    "    for i in range(1, 13):\n",
    "#         if feature == 'place':\n",
    "#             na_features_dict[feature][i] = tr_data.loc[tr_data.month == i, feature].mode().values[0]\n",
    "#         else:\n",
    "            val = tr_data.loc[tr_data.month == i, feature].mean()\n",
    "            if (val is np.nan)&(feature == 'discharge'):\n",
    "                na_features_dict[feature][i] = -1  # признак если среднего расхода воды не знаем или не замеряется на посту\n",
    "            elif val is np.nan:\n",
    "                na_features_dict[feature][i] = 0.0\n",
    "            else:\n",
    "                na_features_dict[feature][i] = val\n",
    "\n",
    "na_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "canadian-conference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stage_avg</th>\n",
       "      <th>stage_min</th>\n",
       "      <th>stage_max</th>\n",
       "      <th>temp</th>\n",
       "      <th>water_code</th>\n",
       "      <th>ice_thickness</th>\n",
       "      <th>snow_height</th>\n",
       "      <th>place</th>\n",
       "      <th>discharge</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>53.788618</td>\n",
       "      <td>31.626016</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-03</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>53.788618</td>\n",
       "      <td>31.626016</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-04</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>53.788618</td>\n",
       "      <td>31.626016</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-05</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3019</td>\n",
       "      <td>1985-01-06</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>53.788618</td>\n",
       "      <td>31.626016</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id       date  stage_avg  stage_min  stage_max  temp water_code  \\\n",
       "1        3019 1985-01-02      -23.0      -23.0      -23.0   0.0         16   \n",
       "2        3019 1985-01-03      -23.0      -23.0      -23.0   0.0         16   \n",
       "3        3019 1985-01-04      -24.0      -24.0      -24.0   0.0         16   \n",
       "4        3019 1985-01-05      -24.0      -24.0      -24.0   0.0         16   \n",
       "5        3019 1985-01-06      -24.0      -24.0      -24.0   0.0         16   \n",
       "\n",
       "   ice_thickness  snow_height  place  discharge  year  month  day  \\\n",
       "1      53.788618    31.626016      0       -1.0  1985      1    2   \n",
       "2      53.788618    31.626016      0       -1.0  1985      1    3   \n",
       "3      53.788618    31.626016      0       -1.0  1985      1    4   \n",
       "4      53.000000    29.000000      1       -1.0  1985      1    5   \n",
       "5      53.788618    31.626016      0       -1.0  1985      1    6   \n",
       "\n",
       "   delta_stage_max  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3             -1.0  \n",
       "4              0.0  \n",
       "5              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11603 entries, 1 to 11603\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   station_id       11603 non-null  int64         \n",
      " 1   date             11603 non-null  datetime64[ns]\n",
      " 2   stage_avg        11603 non-null  float64       \n",
      " 3   stage_min        11603 non-null  float64       \n",
      " 4   stage_max        11603 non-null  float64       \n",
      " 5   temp             11603 non-null  float64       \n",
      " 6   water_code       11603 non-null  object        \n",
      " 7   ice_thickness    11603 non-null  float64       \n",
      " 8   snow_height      11603 non-null  float64       \n",
      " 9   place            11603 non-null  int8          \n",
      " 10  discharge        11603 non-null  float64       \n",
      " 11  year             11603 non-null  int64         \n",
      " 12  month            11603 non-null  int64         \n",
      " 13  day              11603 non-null  int64         \n",
      " 14  delta_stage_max  11603 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(4), int8(1), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# заполняем пропуски\n",
    "for col in na_features:\n",
    "    for i in range(1,13):\n",
    "#         tr_data.loc[tr_data.month == i, col].fillna(value=na_features_dict[col][i], inplace=True)  # не работает...\n",
    "        tr_data.loc[(tr_data.month == i)&(tr_data[col].isna()), col] = na_features_dict[col][i]\n",
    "display(tr_data.head())\n",
    "tr_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-democrat",
   "metadata": {},
   "source": [
    "### Гидрологические данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "engaged-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11603 entries, 1 to 11603\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   station_id       11603 non-null  int64         \n",
      " 1   date             11603 non-null  datetime64[ns]\n",
      " 2   stage_avg        11603 non-null  float64       \n",
      " 3   stage_min        11603 non-null  float64       \n",
      " 4   stage_max        11603 non-null  float64       \n",
      " 5   temp             11603 non-null  float64       \n",
      " 6   water_code       11603 non-null  object        \n",
      " 7   ice_thickness    11603 non-null  float64       \n",
      " 8   snow_height      11603 non-null  float64       \n",
      " 9   place            11603 non-null  int8          \n",
      " 10  discharge        11603 non-null  float64       \n",
      " 11  year             11603 non-null  int64         \n",
      " 12  month            11603 non-null  int64         \n",
      " 13  day              11603 non-null  int64         \n",
      " 14  delta_stage_max  11603 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(4), int8(1), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tr_data = df_preprocessing(train_df, kirensk_dict['id'])\n",
    "tr_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "short-cannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11603 entries, 0 to 11602\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   date                11603 non-null  datetime64[ns]\n",
      " 1   stage_avg_3087      11603 non-null  float64       \n",
      " 2   stage_min_3087      11603 non-null  float64       \n",
      " 3   stage_max_3087      11603 non-null  float64       \n",
      " 4   temp_3087           11603 non-null  float64       \n",
      " 5   water_code_3087     11603 non-null  object        \n",
      " 6   ice_thickness_3087  11603 non-null  float64       \n",
      " 7   snow_height_3087    11603 non-null  float64       \n",
      " 8   place_3087          11603 non-null  int8          \n",
      " 9   discharge_3087      11603 non-null  float64       \n",
      " 10  stage_avg_3021      11603 non-null  float64       \n",
      " 11  stage_min_3021      11603 non-null  float64       \n",
      " 12  stage_max_3021      11603 non-null  float64       \n",
      " 13  temp_3021           11603 non-null  float64       \n",
      " 14  water_code_3021     11603 non-null  object        \n",
      " 15  ice_thickness_3021  11603 non-null  float64       \n",
      " 16  snow_height_3021    11603 non-null  float64       \n",
      " 17  place_3021          11603 non-null  int8          \n",
      " 18  discharge_3021      11603 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int8(2), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# соберём данные со смежных постов, выделенных в словаре по данному целевому посту\n",
    "mapper = dict()\n",
    "use_feature = ['date', 'stage_avg', 'stage_min','stage_max', 'temp', 'water_code', 'ice_thickness','snow_height', \n",
    "               'place', 'discharge']\n",
    "\n",
    "for n, st in enumerate(kirensk_dict['gydro_st']):\n",
    "    if n == 0:\n",
    "        # данные с поста\n",
    "        df = df_preprocessing(train_df, st)\n",
    "        df = df[use_feature]\n",
    "        for col in [x for x in use_feature if x not in ['date']]:\n",
    "            mapper[col] = f'{col}_{st}'\n",
    "        gydro_st = df.rename(columns=mapper)\n",
    "    else:\n",
    "        # данные с поста\n",
    "        df = df_preprocessing(train_df, st)\n",
    "        df = df[use_feature]\n",
    "        for col in [x for x in use_feature if x not in ['date']]:\n",
    "            mapper[col] = f'{col}_{st}'\n",
    "        df.rename(columns=mapper, inplace=True)\n",
    "        gydro_st = pd.merge(gydro_st, df, on='date')\n",
    "\n",
    "gydro_st.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "likely-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11603 entries, 0 to 11602\n",
      "Data columns (total 33 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   station_id          11603 non-null  int64         \n",
      " 1   date                11603 non-null  datetime64[ns]\n",
      " 2   stage_avg           11603 non-null  float64       \n",
      " 3   stage_min           11603 non-null  float64       \n",
      " 4   stage_max           11603 non-null  float64       \n",
      " 5   temp                11603 non-null  float64       \n",
      " 6   water_code          11603 non-null  object        \n",
      " 7   ice_thickness       11603 non-null  float64       \n",
      " 8   snow_height         11603 non-null  float64       \n",
      " 9   place               11603 non-null  int8          \n",
      " 10  discharge           11603 non-null  float64       \n",
      " 11  year                11603 non-null  int64         \n",
      " 12  month               11603 non-null  int64         \n",
      " 13  day                 11603 non-null  int64         \n",
      " 14  delta_stage_max     11603 non-null  float64       \n",
      " 15  stage_avg_3087      11603 non-null  float64       \n",
      " 16  stage_min_3087      11603 non-null  float64       \n",
      " 17  stage_max_3087      11603 non-null  float64       \n",
      " 18  temp_3087           11603 non-null  float64       \n",
      " 19  water_code_3087     11603 non-null  object        \n",
      " 20  ice_thickness_3087  11603 non-null  float64       \n",
      " 21  snow_height_3087    11603 non-null  float64       \n",
      " 22  place_3087          11603 non-null  int8          \n",
      " 23  discharge_3087      11603 non-null  float64       \n",
      " 24  stage_avg_3021      11603 non-null  float64       \n",
      " 25  stage_min_3021      11603 non-null  float64       \n",
      " 26  stage_max_3021      11603 non-null  float64       \n",
      " 27  temp_3021           11603 non-null  float64       \n",
      " 28  water_code_3021     11603 non-null  object        \n",
      " 29  ice_thickness_3021  11603 non-null  float64       \n",
      " 30  snow_height_3021    11603 non-null  float64       \n",
      " 31  place_3021          11603 non-null  int8          \n",
      " 32  discharge_3021      11603 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(22), int64(4), int8(3), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# сводные данные по целевому посту и его окресных гидропостов\n",
    "kirensk_df = pd.merge(tr_data, gydro_st, on='date')\n",
    "kirensk_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-cherry",
   "metadata": {},
   "source": [
    "### Метеорологические данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "robust-playback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30028\n",
      "(12279, 38)\n",
      "1 30219\n",
      "(11363, 38)\n",
      "2 30328\n",
      "(11834, 38)\n",
      "3 30337\n",
      "(12279, 38)\n",
      "4 30433\n",
      "(12310, 38)\n",
      "5 30230\n",
      "(12279, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_st = make_meteo_df(\n",
    "    pd.read_csv(f'{RAWDATADIR}/track_2_package/meteo_3hours.csv', parse_dates=['date_local']),\n",
    "    kirensk_dict['meteo_st']\n",
    ")\n",
    "sum(meteo_st.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-terrorist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-suite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-sperm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-vertex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-gather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "meaning-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3666552, 94)\n",
      "(3666552, 94)\n",
      "(3666552, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# метеоданные\n",
    "meteo_df = pd.read_csv(f'{RAWDATADIR}/track_2_package/meteo_3hours.csv', parse_dates=['date_local'])\n",
    "\n",
    "# Замена np.nan'ами неподтверждённых или опровергнутых данных\n",
    "_qual_cols = list(meteo_df.filter(regex='_qual$').columns)\n",
    "print(meteo_df.shape)\n",
    "for col in _qual_cols:\n",
    "    meteo_df = mute_untrastable(meteo_df, col)\n",
    "print(meteo_df.shape)\n",
    "\n",
    "features = pd.Series(_qual_cols)\n",
    "spl_feat = []\n",
    "for n, f in enumerate(features):\n",
    "    spl = features.values[n].split('_')\n",
    "    spl_feat.append(('_'.join(spl[:len(spl)-1])))\n",
    "    \n",
    "use_feature = ['station_id', 'date_local', 'month_local'] + spl_feat\n",
    "\n",
    "meteo_data = meteo_df[use_feature].copy()\n",
    "print(meteo_data.shape)\n",
    "\n",
    "del meteo_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optimum-politics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458319, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# аггрегация данных с дискретностью 1 день\n",
    "meteo_1day = meteo_data.groupby(['station_id', 'date_local']).median()\n",
    "meteo_1day.reset_index(inplace=True)\n",
    "print(meteo_1day.shape)\n",
    "\n",
    "del meteo_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "olympic-force",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12279, 38)\n",
      "1 30219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11363, 38)\n",
      "2 30328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11834, 38)\n",
      "3 30337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12279, 38)\n",
      "4 30433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12310, 38)\n",
      "5 30230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12279, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12310, 218)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = dict()\n",
    "use_feature = ['date_local', 'month_local'] + spl_feat\n",
    "\n",
    "# берём данные по нужным станциям\n",
    "for n, st in enumerate(kirensk_dict['meteo_st']):\n",
    "    print(n, st)\n",
    "    if n == 0:\n",
    "        df = meteo_data_processing(meteo_1day, st)\n",
    "        df = df[use_feature]\n",
    "        print(df.shape)\n",
    "        for col in spl_feat:\n",
    "            mapper[col] = f'{col}_{st}'\n",
    "        meteo_st = df.rename(columns=mapper)\n",
    "    else:\n",
    "        df = meteo_data_processing(meteo_1day, st)\n",
    "        df = df[use_feature]\n",
    "        print(df.shape)\n",
    "        for col in spl_feat:\n",
    "            mapper[col] = f'{col}_{st}'\n",
    "        df.rename(columns=mapper, inplace=True)\n",
    "        meteo_st = pd.merge(meteo_st, df, how='outer', on=['date_local', 'month_local'])\n",
    "\n",
    "meteo_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "digital-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12310, 218)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "enormous-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_local</th>\n",
       "      <th>month_local</th>\n",
       "      <th>horizontal_visibility_30028</th>\n",
       "      <th>cloud_amount_total_30028</th>\n",
       "      <th>cloud_amount_low_level_30028</th>\n",
       "      <th>cloud_form_high_level_30028</th>\n",
       "      <th>cloud_form_middle_level_30028</th>\n",
       "      <th>cloud_form_vertical_develop_30028</th>\n",
       "      <th>cloud_form_strat_stratocum_30028</th>\n",
       "      <th>cloud_form_strat_rain_30028</th>\n",
       "      <th>...</th>\n",
       "      <th>air_temperature_max_before_30230</th>\n",
       "      <th>air_max_temperature_30230</th>\n",
       "      <th>water_vapour_partial_pressure_30230</th>\n",
       "      <th>relative_humidity_30230</th>\n",
       "      <th>vapour_pressure_deficit_30230</th>\n",
       "      <th>dew_point_temperature_30230</th>\n",
       "      <th>pressure_30230</th>\n",
       "      <th>pressure_sea_level_30230</th>\n",
       "      <th>barometric_tendency_characteristic_30230</th>\n",
       "      <th>barometric_tendency_30230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12305</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12306</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12307</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12308</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_local  month_local  horizontal_visibility_30028  \\\n",
       "12305 2020-01-27            1                          NaN   \n",
       "12306 2020-01-28            1                          NaN   \n",
       "12307 2020-01-29            1                          NaN   \n",
       "12308 2020-01-30            1                          NaN   \n",
       "12309 2020-01-31            1                          NaN   \n",
       "\n",
       "       cloud_amount_total_30028  cloud_amount_low_level_30028  \\\n",
       "12305                       NaN                           NaN   \n",
       "12306                       NaN                           NaN   \n",
       "12307                       NaN                           NaN   \n",
       "12308                       NaN                           NaN   \n",
       "12309                       NaN                           NaN   \n",
       "\n",
       "       cloud_form_high_level_30028  cloud_form_middle_level_30028  \\\n",
       "12305                          NaN                            NaN   \n",
       "12306                          NaN                            NaN   \n",
       "12307                          NaN                            NaN   \n",
       "12308                          NaN                            NaN   \n",
       "12309                          NaN                            NaN   \n",
       "\n",
       "       cloud_form_vertical_develop_30028  cloud_form_strat_stratocum_30028  \\\n",
       "12305                                NaN                               NaN   \n",
       "12306                                NaN                               NaN   \n",
       "12307                                NaN                               NaN   \n",
       "12308                                NaN                               NaN   \n",
       "12309                                NaN                               NaN   \n",
       "\n",
       "       cloud_form_strat_rain_30028  ...  air_temperature_max_before_30230  \\\n",
       "12305                          NaN  ...                               NaN   \n",
       "12306                          NaN  ...                               NaN   \n",
       "12307                          NaN  ...                               NaN   \n",
       "12308                          NaN  ...                               NaN   \n",
       "12309                          NaN  ...                               NaN   \n",
       "\n",
       "       air_max_temperature_30230  water_vapour_partial_pressure_30230  \\\n",
       "12305                        NaN                                  NaN   \n",
       "12306                        NaN                                  NaN   \n",
       "12307                        NaN                                  NaN   \n",
       "12308                        NaN                                  NaN   \n",
       "12309                        NaN                                  NaN   \n",
       "\n",
       "       relative_humidity_30230  vapour_pressure_deficit_30230  \\\n",
       "12305                      NaN                            NaN   \n",
       "12306                      NaN                            NaN   \n",
       "12307                      NaN                            NaN   \n",
       "12308                      NaN                            NaN   \n",
       "12309                      NaN                            NaN   \n",
       "\n",
       "       dew_point_temperature_30230  pressure_30230  pressure_sea_level_30230  \\\n",
       "12305                          NaN             NaN                       NaN   \n",
       "12306                          NaN             NaN                       NaN   \n",
       "12307                          NaN             NaN                       NaN   \n",
       "12308                          NaN             NaN                       NaN   \n",
       "12309                          NaN             NaN                       NaN   \n",
       "\n",
       "       barometric_tendency_characteristic_30230  barometric_tendency_30230  \n",
       "12305                                       NaN                        NaN  \n",
       "12306                                       NaN                        NaN  \n",
       "12307                                       NaN                        NaN  \n",
       "12308                                       NaN                        NaN  \n",
       "12309                                       NaN                        NaN  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_st.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "married-benchmark",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/home/msemezhov/.local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "        # находим значения для заполнения праметров с пропусками, учитывая специфику каждого месяца\n",
    "        features_dict = dict()\n",
    "        features = [x for x in meteo_st.columns if x not in ['date_local', 'month_local']]\n",
    "        for f in features:\n",
    "            features_dict[f] = dict()\n",
    "        for feature in features:\n",
    "            for i in range(1, 13):\n",
    "                val = meteo_st.loc[meteo_st.month_local == i, feature].median()\n",
    "                if (val is not np.nan)|(val is not pd.NA)|(val != 'nan'):\n",
    "                    features_dict[feature][i] = val\n",
    "                else:\n",
    "                    features_dict[feature][i] = -777\n",
    "#         features_dict                \n",
    "        # заполняем пропуски\n",
    "        for col in features:\n",
    "            for i in range(1,13):\n",
    "                meteo_st.loc[(meteo_st.month_local == i)&(meteo_st[col].isna()), col] = features_dict[col][i]\n",
    "                \n",
    "        meteo_st.fillna(-777, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "complicated-politics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_local</th>\n",
       "      <th>month_local</th>\n",
       "      <th>horizontal_visibility_30028</th>\n",
       "      <th>cloud_amount_total_30028</th>\n",
       "      <th>cloud_amount_low_level_30028</th>\n",
       "      <th>cloud_form_high_level_30028</th>\n",
       "      <th>cloud_form_middle_level_30028</th>\n",
       "      <th>cloud_form_vertical_develop_30028</th>\n",
       "      <th>cloud_form_strat_stratocum_30028</th>\n",
       "      <th>cloud_form_strat_rain_30028</th>\n",
       "      <th>...</th>\n",
       "      <th>air_temperature_max_before_30230</th>\n",
       "      <th>air_max_temperature_30230</th>\n",
       "      <th>water_vapour_partial_pressure_30230</th>\n",
       "      <th>relative_humidity_30230</th>\n",
       "      <th>vapour_pressure_deficit_30230</th>\n",
       "      <th>dew_point_temperature_30230</th>\n",
       "      <th>pressure_30230</th>\n",
       "      <th>pressure_sea_level_30230</th>\n",
       "      <th>barometric_tendency_characteristic_30230</th>\n",
       "      <th>barometric_tendency_30230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12305</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.15</td>\n",
       "      <td>-24.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-29.05</td>\n",
       "      <td>996.05</td>\n",
       "      <td>1032.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12306</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.15</td>\n",
       "      <td>-24.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-29.05</td>\n",
       "      <td>996.05</td>\n",
       "      <td>1032.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12307</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.15</td>\n",
       "      <td>-24.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-29.05</td>\n",
       "      <td>996.05</td>\n",
       "      <td>1032.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12308</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.15</td>\n",
       "      <td>-24.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-29.05</td>\n",
       "      <td>996.05</td>\n",
       "      <td>1032.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.15</td>\n",
       "      <td>-24.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-29.05</td>\n",
       "      <td>996.05</td>\n",
       "      <td>1032.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_local  month_local  horizontal_visibility_30028  \\\n",
       "12305 2020-01-27            1                         97.0   \n",
       "12306 2020-01-28            1                         97.0   \n",
       "12307 2020-01-29            1                         97.0   \n",
       "12308 2020-01-30            1                         97.0   \n",
       "12309 2020-01-31            1                         97.0   \n",
       "\n",
       "       cloud_amount_total_30028  cloud_amount_low_level_30028  \\\n",
       "12305                       6.5                           0.0   \n",
       "12306                       6.5                           0.0   \n",
       "12307                       6.5                           0.0   \n",
       "12308                       6.5                           0.0   \n",
       "12309                       6.5                           0.0   \n",
       "\n",
       "       cloud_form_high_level_30028  cloud_form_middle_level_30028  \\\n",
       "12305                          1.0                            0.0   \n",
       "12306                          1.0                            0.0   \n",
       "12307                          1.0                            0.0   \n",
       "12308                          1.0                            0.0   \n",
       "12309                          1.0                            0.0   \n",
       "\n",
       "       cloud_form_vertical_develop_30028  cloud_form_strat_stratocum_30028  \\\n",
       "12305                                0.0                               0.0   \n",
       "12306                                0.0                               0.0   \n",
       "12307                                0.0                               0.0   \n",
       "12308                                0.0                               0.0   \n",
       "12309                                0.0                               0.0   \n",
       "\n",
       "       cloud_form_strat_rain_30028  ...  air_temperature_max_before_30230  \\\n",
       "12305                          0.0  ...                            -23.15   \n",
       "12306                          0.0  ...                            -23.15   \n",
       "12307                          0.0  ...                            -23.15   \n",
       "12308                          0.0  ...                            -23.15   \n",
       "12309                          0.0  ...                            -23.15   \n",
       "\n",
       "       air_max_temperature_30230  water_vapour_partial_pressure_30230  \\\n",
       "12305                     -24.35                                 0.57   \n",
       "12306                     -24.35                                 0.57   \n",
       "12307                     -24.35                                 0.57   \n",
       "12308                     -24.35                                 0.57   \n",
       "12309                     -24.35                                 0.57   \n",
       "\n",
       "       relative_humidity_30230  vapour_pressure_deficit_30230  \\\n",
       "12305                     77.5                          0.135   \n",
       "12306                     77.5                          0.135   \n",
       "12307                     77.5                          0.135   \n",
       "12308                     77.5                          0.135   \n",
       "12309                     77.5                          0.135   \n",
       "\n",
       "       dew_point_temperature_30230  pressure_30230  pressure_sea_level_30230  \\\n",
       "12305                       -29.05          996.05                    1032.4   \n",
       "12306                       -29.05          996.05                    1032.4   \n",
       "12307                       -29.05          996.05                    1032.4   \n",
       "12308                       -29.05          996.05                    1032.4   \n",
       "12309                       -29.05          996.05                    1032.4   \n",
       "\n",
       "       barometric_tendency_characteristic_30230  barometric_tendency_30230  \n",
       "12305                                       5.0                        0.8  \n",
       "12306                                       5.0                        0.8  \n",
       "12307                                       5.0                        0.8  \n",
       "12308                                       5.0                        0.8  \n",
       "12309                                       5.0                        0.8  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_st.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bound-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(meteo_st.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-marathon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "southeast-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30028, 30219, 30328, 30337, 30433, 30230]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kirensk_dict['meteo_st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-gibson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-robertson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
